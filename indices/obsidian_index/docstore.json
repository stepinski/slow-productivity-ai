{"docstore/metadata": {"c6fcb6e8-d381-407c-925f-603220dc5e28": {"doc_hash": "6f2a8dbb2db90af0024b6d0313544b2cc1bfb22bb4b357ae8757411134d66332"}, "6f0d091d-d372-4ccd-b7f9-9f39ab8d271c": {"doc_hash": "ca04cf65a785f980a5c60e20755199dc558a71c072defb78a1852f2f90e07137"}, "00140d49-fe53-4614-b97e-3d76783c7d6c": {"doc_hash": "eedfa7cf1d2e4bbe56552b57d75fdb43868f5558d6432198b807144a617e916e"}, "579982a0-8b10-4f70-a5ae-a732543de601": {"doc_hash": "7200408dcd9595c8c11432d075c5c27ea76ad8001f6351047bbf5f26573efd7c"}, "1cc7feb7-7921-44cb-81de-f04f84d3ee4f": {"doc_hash": "8a919f03189503b4eb08323087ba98c74b903bbd07645f4f2e4d2dfbd2aecac8"}, "9205f1a4-d34c-4d87-ab03-56ed03e9a1c6": {"doc_hash": "3ad250e64a5cc59933353c0e2ae64afe3a90f50ac6e78d9349ec98bdd8cf005b"}, "2f8534ef-48a1-4d6c-bfc3-a111f10fda9c": {"doc_hash": "c8c05ef501dc67e22dd58d714a140db0c0c86eb4cc35967f309db50d9874b2ec"}, "c9131b7e-b636-454e-805e-90581068de64": {"doc_hash": "f5c646d1391780872a4d19be9c2084a91ffc83bcbf21bf67994eb4c5bc2b3864"}, "2ec865cf-e9fe-47a2-8e3e-1061a24bab5e": {"doc_hash": "0333e2d64631586e89736bc261359c91ef21741370ccac84bf36d361147fc210"}, "f5b274b5-39d7-4b1f-97a8-39fdd91a769f": {"doc_hash": "75a67444d2aa32f9687ba06e2a775728e04c705dcf6a0698b427dd69559d59dd"}, "2cfb4c26-85e2-4a90-952a-68981772a34f": {"doc_hash": "68ab432ce07192fe22771a6ca450a469007375b096f21dcdbf41a9de85b062b3"}, "73e585e7-34d9-471d-b8da-40e582ea63a3": {"doc_hash": "5b457cc1416e4de70c2b50f2a1147504da44d4f35faafb70aa9c6384ab0b261c"}, "d08f0456-7928-49f4-9b0e-2ac7c5dfdc07": {"doc_hash": "1b4ea450c8168177cf2754c73ac2dc0ba159d1ad10431014415408c532494fa1"}, "54f95092-ae46-43ac-bf40-ce7ec55aed42": {"doc_hash": "102151be44a08e3f986f3d7deb7efe96ecb495b12285b894d53e2f6b311482e8"}, "ab1fb6b1-a56b-48bb-b17d-051e6e01b935": {"doc_hash": "c5a1f13a618ebd18719865a40092eb96ac30ea4b58d451f06b82ca91ae99eccc"}, "7441af7e-c080-4d59-8fa6-429c30d46faa": {"doc_hash": "41ff005390680b8595ed325c900e5069acdc4ca0423b83943cb686c0b6a0817b"}, "0dbdaf45-21a5-4215-9ad2-dc352812ee1a": {"doc_hash": "53017b675222a95cd07f9de8680b1634d30b930fa778a2ead0951c122c8a33ac"}, "30d88e7b-2371-49cd-9a31-ebadd9044b9b": {"doc_hash": "5a6c48d89db561421dd55574298ed3cd66b75b0266082a7ca8f0151020da446a"}, "d7986193-59ec-42af-af93-28c4c52ad340": {"doc_hash": "e3d8bc3394a56e77a5112248da6cc3ee45455386dbc3d6a1e72416a0863489e1"}, "a061dff7-55ff-4bbd-9719-f08c1937ee0b": {"doc_hash": "6e51a7ed69806195f1ebc4a2868d31a3ad95f25755b11ccc8e3a836d2fc3daf6"}, "2cbf69c1-1d98-406e-a2b0-60d22243c74d": {"doc_hash": "4c89b876ba6b958fdada7cda97e92de4779bdae0e4560811c42174d918cf82b7", "ref_doc_id": "c6fcb6e8-d381-407c-925f-603220dc5e28"}, "0a5ef95e-e2fe-47d4-b86f-ca9d1650652f": {"doc_hash": "0eeca8c809df50a0c0b661e21a6edcb3a8b0b4fa806c82e8500e04aa27e4d4ed", "ref_doc_id": "c6fcb6e8-d381-407c-925f-603220dc5e28"}, "5752e795-6917-47b0-b066-09fa4e500183": {"doc_hash": "4ab28edffddd9ca2539ac6890094ffb5a9630a8dcee88ebcb4b12db57092b535", "ref_doc_id": "6f0d091d-d372-4ccd-b7f9-9f39ab8d271c"}, "b2b185ea-6c74-4f65-af21-db1cb39f21f3": {"doc_hash": "fa9fcbd74135ea8a7d4d180a40407b7f405e5ec2154ce52784f34a2b4093fb7a", "ref_doc_id": "6f0d091d-d372-4ccd-b7f9-9f39ab8d271c"}, "cf1b47c9-6a63-4e1b-8c56-b00ffe126904": {"doc_hash": "5f8861129ff4c209288010c7473539f34b58311fae4a22ae3b15296c9378d0c7", "ref_doc_id": "00140d49-fe53-4614-b97e-3d76783c7d6c"}, "0220d925-d34a-43fd-b6ab-4a5468486736": {"doc_hash": "0debfa75b2109a651bbd60021dd110f9a641448d471589b7a82bd648bc646ecd", "ref_doc_id": "00140d49-fe53-4614-b97e-3d76783c7d6c"}, "6fe602df-8a43-4a9d-9820-d1163691f80b": {"doc_hash": "c7fd9e17c31a04cc172c99eebec25f080261eef968748df0ba15579d5bc823be", "ref_doc_id": "579982a0-8b10-4f70-a5ae-a732543de601"}, "731c2bb4-4e3c-46d2-be43-68810f32dcfa": {"doc_hash": "00ba74c18cf34b1cd7fba3e4a45bcab22f98c6a6303d7c951a87a84bad6d97d1", "ref_doc_id": "579982a0-8b10-4f70-a5ae-a732543de601"}, "209a5652-7708-4486-a6b3-dba05c0fe6d0": {"doc_hash": "476885209fed7beb452832317cd3543ec8be43bc9c7756056fffded76c033578", "ref_doc_id": "1cc7feb7-7921-44cb-81de-f04f84d3ee4f"}, "d1e3b8f8-f6c1-4a57-a9d9-8d1389ab4a50": {"doc_hash": "cc849ba946d0b30118c41944ac476f18f32dd383099834ce18aefa17cc43ebe8", "ref_doc_id": "1cc7feb7-7921-44cb-81de-f04f84d3ee4f"}, "aaee6495-da9a-40e4-b490-3277639432b6": {"doc_hash": "b064597d2f28e201830b669a146c67b4f01a5e8c67205f5585b7401ce25f857d", "ref_doc_id": "1cc7feb7-7921-44cb-81de-f04f84d3ee4f"}, "2cec6d4d-f10f-4436-9f5a-efc5b07d1b00": {"doc_hash": "b93a9f5cd7f6b855f43f640a67fa47d042276037aff64353cc25d7d2efb01fdd", "ref_doc_id": "9205f1a4-d34c-4d87-ab03-56ed03e9a1c6"}, "e1bbed59-a25d-46f0-b67e-f67925f06c5f": {"doc_hash": "a2abbedd7338eb131b29f0762635d1d13ade071b06ca337fe07e1145a88fb703", "ref_doc_id": "9205f1a4-d34c-4d87-ab03-56ed03e9a1c6"}, "27d87978-388f-41c9-8f2d-586ae30c1922": {"doc_hash": "149bde4d96c434ec839d6a194ca822832b4b2cada2e490981500973e976d75a7", "ref_doc_id": "9205f1a4-d34c-4d87-ab03-56ed03e9a1c6"}, "51c38d12-84b8-48c2-9d47-2a65540b7327": {"doc_hash": "603daa0f7b79691a649bc96559bf30e05e3298dd40b9091aefffaebe9b5091ae", "ref_doc_id": "2f8534ef-48a1-4d6c-bfc3-a111f10fda9c"}, "6e5c8941-bfb7-40ae-9c39-e95199b5a90b": {"doc_hash": "6b4fc1ce19cce638a64ff0f751fc97a089edd404e8513ca720a7866fbd4a4976", "ref_doc_id": "2f8534ef-48a1-4d6c-bfc3-a111f10fda9c"}, "76568e15-15f6-4d8b-af35-ee64625316ff": {"doc_hash": "0a54481a8f6a00de60c23e961a8d82963d367b9b17d52bc3f145f9f5c6e5cf58", "ref_doc_id": "2f8534ef-48a1-4d6c-bfc3-a111f10fda9c"}, "614850f2-eb37-4e8b-aef4-e204324ae9b5": {"doc_hash": "2ae9032114cda97c4eb229b85fd29f61f2f2864f69d8029483d65da5ec0eefe8", "ref_doc_id": "c9131b7e-b636-454e-805e-90581068de64"}, "4745628e-ab0f-4ab6-870d-b23b79b8e616": {"doc_hash": "d868ed2dd196765676548d2da23872e605bce96f84e120fd767fea0c6615cfc2", "ref_doc_id": "2ec865cf-e9fe-47a2-8e3e-1061a24bab5e"}, "8892770e-ead6-4bb6-ae8f-02ffb2b4b571": {"doc_hash": "47d9d861d96ae457028645be7561690ad3fd7e3eef9bb952cbc8f57965b1ba12", "ref_doc_id": "f5b274b5-39d7-4b1f-97a8-39fdd91a769f"}, "e3db68b8-f175-4ef7-a276-f8ddfec754e5": {"doc_hash": "833c683d76ad8e4794b003f0e0f63a9aca2ef1a76a3fa2e62530a37b3f12c539", "ref_doc_id": "2cfb4c26-85e2-4a90-952a-68981772a34f"}, "1e572200-cde2-4669-a957-cf3993646f6d": {"doc_hash": "66bd87b75f225c4706a3693cdfe12152a66d38339b2fcfe3f3bb51e2091e1d09", "ref_doc_id": "73e585e7-34d9-471d-b8da-40e582ea63a3"}, "3aa57d6a-6eec-441c-b5a1-14086a37061c": {"doc_hash": "82d54ffc89b00f0cb681bb7cb8ae85ba351c19aa7bdee6d3571e35419f23956d", "ref_doc_id": "d08f0456-7928-49f4-9b0e-2ac7c5dfdc07"}, "6da488a5-5b5e-45b4-8c58-ff75f3ad3444": {"doc_hash": "49bad478ae6c707fde171a49324d6dd65ce83615a6234950c71c72730d1e9f8a", "ref_doc_id": "54f95092-ae46-43ac-bf40-ce7ec55aed42"}, "c908f14b-6a02-4674-9421-5f9b2574dcbe": {"doc_hash": "e41f14b38401cf351f33996aff484594ebb2a4abf548ce3ae826642db01c4728", "ref_doc_id": "ab1fb6b1-a56b-48bb-b17d-051e6e01b935"}, "d8b9a3ea-1c0e-43a1-a006-167d9d1d986b": {"doc_hash": "12224eabba3871aeea42db2c0dff6c753a1c34933d64116143c7fa742f16d013", "ref_doc_id": "7441af7e-c080-4d59-8fa6-429c30d46faa"}, "7d788a1e-ca5e-4e16-abff-3c12148adf70": {"doc_hash": "7a8bba7606bedc84ebc1a16de4738ec4870860010ea840a876bff4a5d31497de", "ref_doc_id": "0dbdaf45-21a5-4215-9ad2-dc352812ee1a"}, "01f84bf8-d56c-42df-b72f-a7e9d331f6ed": {"doc_hash": "5eb255d41abf63262d1978a22f879a06323a54f07837b6c49b0d39ed6edc65d1", "ref_doc_id": "30d88e7b-2371-49cd-9a31-ebadd9044b9b"}, "1957e903-c62e-4c14-bb42-fdb4277e9651": {"doc_hash": "f0969a172b603a699c4beacc26c9bdcc0a40021c740a555fe369cdf74b4f1e4a", "ref_doc_id": "d7986193-59ec-42af-af93-28c4c52ad340"}, "2b794323-5db2-4ee5-ac4c-b93f558915c7": {"doc_hash": "01e642548c9eba32f138b8d554e45204653bd4e240ae493305c9d2b93e87c9d6", "ref_doc_id": "a061dff7-55ff-4bbd-9719-f08c1937ee0b"}}, "docstore/data": {"2cbf69c1-1d98-406e-a2b0-60d22243c74d": {"__data__": {"id_": "2cbf69c1-1d98-406e-a2b0-60d22243c74d", "embedding": null, "metadata": {"page_label": "1", "file_name": "1704.02971 (1).pdf", "file_path": "/Users/unman/ws/slow-productivity-ai/data/1704.02971 (1).pdf", "file_type": "application/pdf", "file_size": 488762, "creation_date": "2025-04-09", "last_modified_date": "2025-03-31"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "c6fcb6e8-d381-407c-925f-603220dc5e28", "node_type": "4", "metadata": {"page_label": "1", "file_name": "1704.02971 (1).pdf", "file_path": "/Users/unman/ws/slow-productivity-ai/data/1704.02971 (1).pdf", "file_type": "application/pdf", "file_size": 488762, "creation_date": "2025-04-09", "last_modified_date": "2025-03-31"}, "hash": "6f2a8dbb2db90af0024b6d0313544b2cc1bfb22bb4b357ae8757411134d66332", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "0a5ef95e-e2fe-47d4-b86f-ca9d1650652f", "node_type": "1", "metadata": {}, "hash": "312c38057b1314e6ccd0933e0d439d7ca53f17788f3408cfae91639ee4962515", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "A Dual-Stage Attention-Based Recurrent Neural Network\nfor Time Series Prediction\nYao Qin1\u2217, Dongjin Song2, Haifeng Chen2, Wei Cheng2, Guofei Jiang2, Garrison W. Cottrell1\n1University of California, San Diego\n2NEC Laboratories America, Inc.\n{yaq007, gary}@eng.ucsd.edu, {dsong, Haifeng, weicheng, gfj}@nec-labs.com\nAbstract\nThe Nonlinear autoregressive exogenous (NARX)\nmodel, which predicts the current value of a time\nseries based upon its previous values as well as the\ncurrent and past values of multiple driving (exoge-\nnous) series, has been studied for decades. De-\nspite the fact that various NARX models have been\ndeveloped, few of them can capture the long-term\ntemporal dependencies appropriately and select the\nrelevant driving series to make predictions. In this\npaper, we propose a dual-stage attention-based re-\ncurrent neural network (DA-RNN) to address these\ntwo issues. In the \ufb01rst stage, we introduce an in-\nput attention mechanism to adaptively extract rel-\nevant driving series ( a.k.a., input features) at each\ntime step by referring to the previous encoder hid-\nden state. In the second stage, we use a temporal\nattention mechanism to select relevant encoder hid-\nden states across all time steps. With this dual-stage\nattention scheme, our model can not only make\npredictions effectively, but can also be easily in-\nterpreted. Thorough empirical studies based upon\nthe SML 2010 dataset and the NASDAQ 100 Stock\ndataset demonstrate that the DA-RNN can outper-\nform state-of-the-art methods for time series pre-\ndiction.\n1 Introduction\nTime series prediction algorithms have been widely applied\nin many areas, e.g., \ufb01nancial market prediction [Wu et al.,\n2013], weather forecasting [Chakraborty et al., 2012 ], and\ncomplex dynamical system analysis [Liu and Hauskrecht,\n2015]. Although the well-known autoregressive moving av-\nerage (ARMA) model [Whittle, 1951 ] and its variants [As-\nteriou and Hall, 2011; Brockwell and Davis, 2009 ] have\nshown their effectiveness for various real world applications,\nthey cannot model nonlinear relationships and do not dif-\nferentiate among the exogenous (driving) input terms. To\naddress this issue, various nonlinear autoregressive exoge-\nnous (NARX) models [Lin et al., 1996; Gao and Er, 2005;\n\u2217Most of this work was performed while the \ufb01rst author was an\nintern at NEC Labs America.\nDiaconescu, 2008; Yan et al., 2013 ] have been developed.\nTypically, given the previous values of the target series,\ni.e. (y1,y2,\u00b7\u00b7\u00b7 ,yt\u22121) with yt\u22121 \u2208 R, as well as the cur-\nrent and past values of n driving (exogenous) series, i.e.,\n(x1,x2,\u00b7\u00b7\u00b7 ,xt) with xt \u2208 Rn, the NARX model aims to\nlearn a nonlinear mapping to the current value of target se-\nries yt, i.e., \u02c6yt = F(y1,y2,\u00b7\u00b7\u00b7 ,yt\u22121,x1,x2,\u00b7\u00b7\u00b7 ,xt), where\nF(\u00b7) is the mapping function to learn.\nDespite the fact that a substantial effort has been made for\ntime series prediction via kernel methods [Chen et al., 2008],\nensemble methods [Bouchachia and Bouchachia, 2008], and\nGaussian processes [Frigola and Rasmussen, 2014], the draw-\nback is that most of these approaches employ a prede\ufb01ned\nnonlinear form and may not be able to capture the true un-\nderlying nonlinear relationship appropriately. Recurrent neu-\nral networks (RNNs) [Rumelhart et al., 1986; Werbos, 1990;\nElman, 1991 ], a type of deep neural network specially de-\nsigned for sequence modeling, have received a great amount\nof attention due to their \ufb02exibility in capturing nonlinear re-\nlationships. In particular, RNNs have shown their success in\nNARX time series forecasting in recent years [Gao and Er,\n2005; Diaconescu, 2008].", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3597, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "0a5ef95e-e2fe-47d4-b86f-ca9d1650652f": {"__data__": {"id_": "0a5ef95e-e2fe-47d4-b86f-ca9d1650652f", "embedding": null, "metadata": {"page_label": "1", "file_name": "1704.02971 (1).pdf", "file_path": "/Users/unman/ws/slow-productivity-ai/data/1704.02971 (1).pdf", "file_type": "application/pdf", "file_size": 488762, "creation_date": "2025-04-09", "last_modified_date": "2025-03-31"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "c6fcb6e8-d381-407c-925f-603220dc5e28", "node_type": "4", "metadata": {"page_label": "1", "file_name": "1704.02971 (1).pdf", "file_path": "/Users/unman/ws/slow-productivity-ai/data/1704.02971 (1).pdf", "file_type": "application/pdf", "file_size": 488762, "creation_date": "2025-04-09", "last_modified_date": "2025-03-31"}, "hash": "6f2a8dbb2db90af0024b6d0313544b2cc1bfb22bb4b357ae8757411134d66332", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "2cbf69c1-1d98-406e-a2b0-60d22243c74d", "node_type": "1", "metadata": {"page_label": "1", "file_name": "1704.02971 (1).pdf", "file_path": "/Users/unman/ws/slow-productivity-ai/data/1704.02971 (1).pdf", "file_type": "application/pdf", "file_size": 488762, "creation_date": "2025-04-09", "last_modified_date": "2025-03-31"}, "hash": "4c89b876ba6b958fdada7cda97e92de4779bdae0e4560811c42174d918cf82b7", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Recurrent neu-\nral networks (RNNs) [Rumelhart et al., 1986; Werbos, 1990;\nElman, 1991 ], a type of deep neural network specially de-\nsigned for sequence modeling, have received a great amount\nof attention due to their \ufb02exibility in capturing nonlinear re-\nlationships. In particular, RNNs have shown their success in\nNARX time series forecasting in recent years [Gao and Er,\n2005; Diaconescu, 2008]. Traditional RNNs, however, suffer\nfrom the problem of vanishing gradients[Bengio et al., 1994]\nand thus have dif\ufb01culty capturing long-term dependencies.\nRecently, long short-term memory units (LSTM) [Hochre-\niter and Schmidhuber, 1997 ] and the gated recurrent unit\n(GRU) [Cho et al., 2014b] have overcome this limitation and\nachieved great success in various applications, e.g., neural\nmachine translation [Bahdanau et al., 2014 ], speech recog-\nnition [Graves et al., 2013], and image processing [Karpathy\nand Li, 2015]. Therefore, it is natural to consider state-of-the-\nart RNN methods,e.g., encoder-decoder networks[Cho et al.,\n2014b; Sutskever et al., 2014] and attention based encoder-\ndecoder networks [Bahdanau et al., 2014], for time series pre-\ndiction.\nBased upon LSTM or GRU units, encoder-decoder net-\nworks [Kalchbrenner and Blunsom, 2013; Cho et al., 2014a;\nCho et al., 2014b; Sutskever et al., 2014] have become popu-\nlar due to their success in machine translation. The key idea\nis to encode the source sentence as a \ufb01xed-length vector and\nuse the decoder to generate a translation. One problem with\nencoder-decoder networks is that their performance will dete-\nriorate rapidly as the length of input sequence increases [Cho\net al., 2014a ]. In time series analysis, this could be a con-\narXiv:1704.02971v4  [cs.LG]  14 Aug 2017", "mimetype": "text/plain", "start_char_idx": 3198, "end_char_idx": 4944, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "5752e795-6917-47b0-b066-09fa4e500183": {"__data__": {"id_": "5752e795-6917-47b0-b066-09fa4e500183", "embedding": null, "metadata": {"page_label": "2", "file_name": "1704.02971 (1).pdf", "file_path": "/Users/unman/ws/slow-productivity-ai/data/1704.02971 (1).pdf", "file_type": "application/pdf", "file_size": 488762, "creation_date": "2025-04-09", "last_modified_date": "2025-03-31"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "6f0d091d-d372-4ccd-b7f9-9f39ab8d271c", "node_type": "4", "metadata": {"page_label": "2", "file_name": "1704.02971 (1).pdf", "file_path": "/Users/unman/ws/slow-productivity-ai/data/1704.02971 (1).pdf", "file_type": "application/pdf", "file_size": 488762, "creation_date": "2025-04-09", "last_modified_date": "2025-03-31"}, "hash": "ca04cf65a785f980a5c60e20755199dc558a71c072defb78a1852f2f90e07137", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "b2b185ea-6c74-4f65-af21-db1cb39f21f3", "node_type": "1", "metadata": {}, "hash": "818da43f96128418567b4763642c7a162b31f04e33594c53c89b2dd8f3eb00dd", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "x\"\ud835\udfcf\nx\"\ud835\udc95\nx\"\ud835\udc7b\nh\ud835\udfcf\nh\ud835\udc95\nh\ud835\udc7b\nTemporal\nAttn\nd\ud835\udc95(\ud835\udfcf\nTemporal \nattention Layer\nEncoder\n\ud835\udc59*\n+\n\ud835\udc59*\n*\n\ud835\udc59*\n,\n\u2026\n\u2026\nSoftmax\n\ud835\udefd*\n+\n\ud835\udefd*\n*\n\ud835\udefd*\n,\n\u2026\nh\ud835\udfcf\nh\ud835\udc95\nh\ud835\udc7b\nc\ud835\udc95(\ud835\udfcf\nLSTM\n\ud835\udc85\ud835\udfd0\n\u2026\nDecoder\nLSTM\nLSTM\n\ud835\udc66+\n\ud835\udc66*(+\n\ud835\udc66,(+\n\ud835\udc662,\n\ud835\udc85\ud835\udc95(\ud835\udfcf\n\ud835\udc85\ud835\udc95\n\u2026\n\ud835\udc85\ud835\udc7b(\ud835\udfcf\nLSTM\n\ud835\udc89\ud835\udfcf\nLSTM\nLSTM\n\ud835\udc89\ud835\udc95(\ud835\udfcf\n\ud835\udc89\ud835\udc95\n\u2026\n\ud835\udc89\ud835\udc7b(\ud835\udfcf\n\u2026\n\u2026\n\u2026\nc\ud835\udfcf\nc\ud835\udc7b(\ud835\udfcf\nx\ud835\udfcf\nx\ud835\udfd0\nx\ud835\udc8f\nDriving series \nof length  \n\u2026\n\u2026\n\ud835\udc52*\n+\n\ud835\udc52*\n6\n\ud835\udc52*\n7\n\ud835\udefc*\n+\n\ud835\udefc*\n6\n\ud835\udefc*\n7\n\u2026\n\ud835\udc65*\n+\n\ud835\udc65*\n6\n\ud835\udc65*\n7\n\ud835\udefc*\n+ \u00b7 \ud835\udc65*\n+\n\ud835\udefc*\n6 \u00b7\ud835\udc65*\n6\n\ud835\udc65*\n7\n\u2026 x\"\ud835\udc95\nNew input \nat time \nInput \nattention Layer\nh\ud835\udc95(\ud835\udfcf\nSoftmax\n\ud835\udefc*\n7 \u00b7\nInput\nAttn\n(a) Input Attention Mechanism (b) Temporal Attention Mechanism\n\u2026\nFigure 1: Graphical illustration of the dual-stage attention-based recurrent neural network. (a) The input attention mechanism computes the\nattention weights \u03b1k\nt for multiple driving series {x1,x2,\u00b7\u00b7\u00b7 ,xn}conditioned on the previous hidden stateht\u22121 in the encoder and then feeds\nthe newly computed \u02dcxt = (\u03b11\nt x1\nt ,\u03b12\nt x2\nt ,\u00b7\u00b7\u00b7 ,\u03b1n\nt xn\nt )\u22a4into the encoder LSTM unit. (b) The temporal attention system computes the attention\nweights \u03b2t\nt based on the previous decoder hidden state dt\u22121 and represents the input information as a weighted sum of the encoder hidden\nstates across all the time steps. The generated context vector ct is then used as an input to the decoder LSTM unit. The output \u02c6yT of the last\ndecoder LSTM unit is the predicted result.\ncern since we usually expect to make predictions based upon\na relatively long segment of the target series as well as driv-\ning series. To resolve this issue, the attention-based encoder-\ndecoder network [Bahdanau et al., 2014] employs an atten-\ntion mechanism to select parts of hidden states across all the\ntime steps. Recently, a hierarchical attention network [Yang\net al., 2016], which uses two layers of attention mechanism\nto select relevant encoder hidden states across all the time\nsteps, was also developed. Although attention-based encoder-\ndecoder networks and hierarchical attention networks have\nshown their ef\ufb01cacy for machine translation, image caption-\ning [Xu et al., 2015], and document classi\ufb01cation, they may\nnot be suitable for time series prediction. This is because\nwhen multiple driving (exogenous) series are available, the\nnetwork cannot explicitly select relevant driving series to\nmake predictions. In addition, they have mainly been used\nfor classi\ufb01cation, rather than time series prediction.\nTo address these aforementioned issues, and inspired by\nsome theories of human attention [H\u00a8ubner et al., 2010] that\nposit that human behavior is well-modeled by a two-stage at-\ntention mechanism, we propose a novel dual-stage attention-\nbased recurrent neural network (DA-RNN) to perform time\nseries prediction. In the \ufb01rst stage, we develop a new atten-\ntion mechanism to adaptively extract the relevant driving se-\nries at each time step by referring to the previous encoder\nhidden state. In the second stage, a temporal attention mech-\nanism is used to select relevant encoder hidden states across\nall time steps.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2896, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "b2b185ea-6c74-4f65-af21-db1cb39f21f3": {"__data__": {"id_": "b2b185ea-6c74-4f65-af21-db1cb39f21f3", "embedding": null, "metadata": {"page_label": "2", "file_name": "1704.02971 (1).pdf", "file_path": "/Users/unman/ws/slow-productivity-ai/data/1704.02971 (1).pdf", "file_type": "application/pdf", "file_size": 488762, "creation_date": "2025-04-09", "last_modified_date": "2025-03-31"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "6f0d091d-d372-4ccd-b7f9-9f39ab8d271c", "node_type": "4", "metadata": {"page_label": "2", "file_name": "1704.02971 (1).pdf", "file_path": "/Users/unman/ws/slow-productivity-ai/data/1704.02971 (1).pdf", "file_type": "application/pdf", "file_size": 488762, "creation_date": "2025-04-09", "last_modified_date": "2025-03-31"}, "hash": "ca04cf65a785f980a5c60e20755199dc558a71c072defb78a1852f2f90e07137", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "5752e795-6917-47b0-b066-09fa4e500183", "node_type": "1", "metadata": {"page_label": "2", "file_name": "1704.02971 (1).pdf", "file_path": "/Users/unman/ws/slow-productivity-ai/data/1704.02971 (1).pdf", "file_type": "application/pdf", "file_size": 488762, "creation_date": "2025-04-09", "last_modified_date": "2025-03-31"}, "hash": "4ab28edffddd9ca2539ac6890094ffb5a9630a8dcee88ebcb4b12db57092b535", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "This is because\nwhen multiple driving (exogenous) series are available, the\nnetwork cannot explicitly select relevant driving series to\nmake predictions. In addition, they have mainly been used\nfor classi\ufb01cation, rather than time series prediction.\nTo address these aforementioned issues, and inspired by\nsome theories of human attention [H\u00a8ubner et al., 2010] that\nposit that human behavior is well-modeled by a two-stage at-\ntention mechanism, we propose a novel dual-stage attention-\nbased recurrent neural network (DA-RNN) to perform time\nseries prediction. In the \ufb01rst stage, we develop a new atten-\ntion mechanism to adaptively extract the relevant driving se-\nries at each time step by referring to the previous encoder\nhidden state. In the second stage, a temporal attention mech-\nanism is used to select relevant encoder hidden states across\nall time steps. These two attention models are well integrated\nwithin an LSTM-based recurrent neural network (RNN) and\ncan be jointly trained using standard back propagation. In\nthis way, the DA-RNN can adaptively select the most rele-\nvant input features as well as capture the long-term temporal\ndependencies of a time series appropriately. To justify the\neffectiveness of the DA-RNN, we compare it with state-of-\nthe-art approaches using the SML 2010 dataset and the NAS-\nDAQ 100 Stock dataset with a large number of driving series.\nExtensive experiments not only demonstrate the effectiveness\nof the proposed approach, but also show that the DA-RNN is\neasy to interpret, and robust to noisy inputs.\n2 Dual-Stage Attention-Based RNN\nIn this section, we \ufb01rst introduce the notation we use in this\nwork and the problem we aim to study. Then, we present the\nmotivation and details of the DA-RNN for time series predic-\ntion.\n2.1 Notation and Problem Statement\nGiven n driving series, i.e., X = ( x1,x2,\u00b7\u00b7\u00b7 ,xn)\u22a4 =\n(x1,x2,\u00b7\u00b7\u00b7 ,xT ) \u2208Rn\u00d7T , where T is the length of window\nsize, we use xk = (xk\n1,xk\n2,\u00b7,xk\nT )\u22a4\u2208RT to represent a driv-\ning series of length T and employ xt = (x1\nt ,x2\nt ,\u00b7\u00b7\u00b7 ,xn\nt )\u22a4\u2208\nRn to denote a vector ofnexogenous (driving) input series at\ntime t.\nTypically, given the previous values of the target series,\ni.e. (y1,y2,\u00b7\u00b7\u00b7 ,yT\u22121) with yt \u2208 R, as well as the cur-\nrent and past values of n driving (exogenous) series, i.e.,\n(x1,x2,\u00b7\u00b7\u00b7 ,xT ) with xt \u2208 Rn, the NARX model aims to\nlearn a nonlinear mapping to the current value of the target\nseries yT :\n\u02c6yT = F(y1,\u00b7\u00b7\u00b7 ,yT\u22121,x1,\u00b7\u00b7\u00b7 ,xT ). (1)\nwhere F(\u00b7) is a nonlinear mapping function we aim to learn.\n2.2 Model\nSome theories of human attention [H\u00a8ubner et al., 2010] ar-\ngue that behavioral results are best modeled by a two-stage\nattention mechanism. The \ufb01rst stage selects the elementary\nstimulus features while the second stage uses categorical in-\nformation to decode the stimulus. Inspired by these theories,\nwe propose a novel dual-stage attention-based recurrent neu-\nral network (DA-RNN) for time series prediction. In the en-\ncoder, we introduce a novel input attention mechanism that\ncan adaptively select the relevant driving series. In the de-\ncoder, a temporal attention mechanism is used to automat-\nically select relevant encoder hidden states across all time\nsteps. For the objective, a square loss is used. With these two\nattention mechanisms, the DA-RNN can adaptively select the\nmost relevant input features and capture the long-term tem-\nporal dependencies of a time series. A graphical illustration\nof the proposed model is shown in Figure 1.", "mimetype": "text/plain", "start_char_idx": 2030, "end_char_idx": 5513, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "cf1b47c9-6a63-4e1b-8c56-b00ffe126904": {"__data__": {"id_": "cf1b47c9-6a63-4e1b-8c56-b00ffe126904", "embedding": null, "metadata": {"page_label": "3", "file_name": "1704.02971 (1).pdf", "file_path": "/Users/unman/ws/slow-productivity-ai/data/1704.02971 (1).pdf", "file_type": "application/pdf", "file_size": 488762, "creation_date": "2025-04-09", "last_modified_date": "2025-03-31"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "00140d49-fe53-4614-b97e-3d76783c7d6c", "node_type": "4", "metadata": {"page_label": "3", "file_name": "1704.02971 (1).pdf", "file_path": "/Users/unman/ws/slow-productivity-ai/data/1704.02971 (1).pdf", "file_type": "application/pdf", "file_size": 488762, "creation_date": "2025-04-09", "last_modified_date": "2025-03-31"}, "hash": "eedfa7cf1d2e4bbe56552b57d75fdb43868f5558d6432198b807144a617e916e", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "0220d925-d34a-43fd-b6ab-4a5468486736", "node_type": "1", "metadata": {}, "hash": "eee1f8c74cb60152e3c5f97eeb3c63b1dd810a33c25178afd6f8121b57399bfa", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Encoder with input attention\nThe encoder is essentially an RNN that encodes the input\nsequences into a feature representation in machine trans-\nlation [Cho et al., 2014b; Sutskever et al., 2014 ]. For\ntime series prediction, given the input sequence X =\n(x1,x2,\u00b7\u00b7\u00b7 ,xT ) with xt \u2208 Rn, where n is the number of\ndriving (exogenous) series, the encoder can be applied to\nlearn a mapping from xt to ht (at time step t) with\nht = f1(ht\u22121,xt), (2)\nwhere ht \u2208Rm is the hidden state of the encoder at timet, m\nis the size of the hidden state, andf1 is a non-linear activation\nfunction that could be an LSTM [Hochreiter and Schmidhu-\nber, 1997] or gated recurrent unit (GRU) [Cho et al., 2014b].\nIn this paper, we use an LSTM unit asf1 to capture long-term\ndependencies. Each LSTM unit has a memory cell with the\nstate st at time t. Access to the memory cell will be controlled\nby three sigmoid gates: forget gate ft, input gate it and output\ngate ot. The update of an LSTM unit can be summarized as\nfollows:\nft = \u03c3(Wf [ht\u22121; xt] +bf ) (3)\nit = \u03c3(Wi[ht\u22121; xt] +bi) (4)\not = \u03c3(Wo[ht\u22121; xt] +bo) (5)\nst = ft \u2299st\u22121 + it \u2299tanh(Ws[ht\u22121; xt] +bs) (6)\nht = ot \u2299tanh(st) (7)\nwhere [ht\u22121; xt] \u2208Rm+n is a concatenation of the previous\nhidden state ht\u22121 and the current input xt. Wf , Wi, Wo,\nWs \u2208Rm\u00d7(m+n), and bf , bi, bo, bs \u2208Rm are parameters to\nlearn. \u03c3and \u2299are a logistic sigmoid function and an element-\nwise multiplication, respectively. The key reason for using\nan LSTM unit is that the cell state sums activities over time,\nwhich can overcome the problem of vanishing gradients and\nbetter capture long-term dependencies of time series.\nInspired by the theory that the human attention system can\nselect elementary stimulus features in the early stages of pro-\ncessing [H\u00a8ubner et al., 2010], we propose an input attention-\nbased encoder that can adaptively select the relevant driving\nseries, which is of practical meaning in time series prediction.\nGiven the k-th input driving (exogenous) series xk =\n(xk\n1,xk\n2,\u00b7\u00b7\u00b7 ,xk\nT )\u22a4\u2208RT , we can construct an input attention\nmechanism via a deterministic attention model, i.e., a mul-\ntilayer perceptron, by referring to the previous hidden state\nht\u22121 and the cell state st\u22121 in the encoder LSTM unit with:\nek\nt = v\u22a4\ne tanh(We[ht\u22121; st\u22121] +Uexk) (8)\nand\n\u03b1k\nt = exp(ek\nt )\u2211n\ni=1 exp(ei\nt), (9)\nwhere ve \u2208RT , We \u2208RT\u00d72m and Ue \u2208RT\u00d7T are parame-\nters to learn.We omit the bias terms in Eqn. (8) to be succinct.\n\u03b1k\nt is the attention weight measuring the importance of the\nk-th input feature (driving series) at time t. A softmax func-\ntion is applied to ek\nt to ensure all the attention weights sum\nto 1. The input attention mechanism is a feed forward net-\nwork that can be jointly trained with other components of the\nRNN. With these attention weights, we can adaptively extract\nthe driving series with\n\u02dcxt = (\u03b11\nt x1\nt ,\u03b12\nt x2\nt ,\u00b7\u00b7\u00b7 ,\u03b1n\nt xn\nt )\u22a4. (10)\nThen the hidden state at time tcan be updated as:\nht = f1(ht\u22121,\u02dcxt), (11)\nwhere f1 is an LSTM unit that can be computed according\nto Eqn. (3) - (7) with xt replaced by the newly computed\n\u02dcxt. With the proposed input attention mechanism, the en-\ncoder can selectively focus on certain driving series rather\nthan treating all the input driving series equally.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3243, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "0220d925-d34a-43fd-b6ab-4a5468486736": {"__data__": {"id_": "0220d925-d34a-43fd-b6ab-4a5468486736", "embedding": null, "metadata": {"page_label": "3", "file_name": "1704.02971 (1).pdf", "file_path": "/Users/unman/ws/slow-productivity-ai/data/1704.02971 (1).pdf", "file_type": "application/pdf", "file_size": 488762, "creation_date": "2025-04-09", "last_modified_date": "2025-03-31"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "00140d49-fe53-4614-b97e-3d76783c7d6c", "node_type": "4", "metadata": {"page_label": "3", "file_name": "1704.02971 (1).pdf", "file_path": "/Users/unman/ws/slow-productivity-ai/data/1704.02971 (1).pdf", "file_type": "application/pdf", "file_size": 488762, "creation_date": "2025-04-09", "last_modified_date": "2025-03-31"}, "hash": "eedfa7cf1d2e4bbe56552b57d75fdb43868f5558d6432198b807144a617e916e", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "cf1b47c9-6a63-4e1b-8c56-b00ffe126904", "node_type": "1", "metadata": {"page_label": "3", "file_name": "1704.02971 (1).pdf", "file_path": "/Users/unman/ws/slow-productivity-ai/data/1704.02971 (1).pdf", "file_type": "application/pdf", "file_size": 488762, "creation_date": "2025-04-09", "last_modified_date": "2025-03-31"}, "hash": "5f8861129ff4c209288010c7473539f34b58311fae4a22ae3b15296c9378d0c7", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "The input attention mechanism is a feed forward net-\nwork that can be jointly trained with other components of the\nRNN. With these attention weights, we can adaptively extract\nthe driving series with\n\u02dcxt = (\u03b11\nt x1\nt ,\u03b12\nt x2\nt ,\u00b7\u00b7\u00b7 ,\u03b1n\nt xn\nt )\u22a4. (10)\nThen the hidden state at time tcan be updated as:\nht = f1(ht\u22121,\u02dcxt), (11)\nwhere f1 is an LSTM unit that can be computed according\nto Eqn. (3) - (7) with xt replaced by the newly computed\n\u02dcxt. With the proposed input attention mechanism, the en-\ncoder can selectively focus on certain driving series rather\nthan treating all the input driving series equally.\nDecoder with temporal attention\nTo predict the output \u02c6yT , we use another LSTM-based recur-\nrent neural network to decode the encoded input information.\nHowever, as suggested by Choet al.[2014a], the performance\nof the encoder-decoder network can deteriorate rapidly as\nthe length of the input sequence increases. Therefore, fol-\nlowing the encoder with input attention, a temporal attention\nmechanism is used in the decoder to adaptively select rele-\nvant encoder hidden states across all time steps. Speci\ufb01cally,\nthe attention weight of each encoder hidden state at time t\nis calculated based upon the previous decoder hidden state\ndt\u22121 \u2208Rp and the cell state of the LSTM unit s\u2032\nt\u22121 \u2208Rp\nwith\nli\nt = v\u22a4\nd tanh(Wd[dt\u22121; s\u2032\nt\u22121] +Udhi), 1 \u2264i\u2264T (12)\nand\n\u03b2i\nt = exp(li\nt)\u2211T\nj=1 exp(lj\nt )\n, (13)\nwhere [dt\u22121; s\u2032\nt\u22121] \u2208 R2p is a concatenation of the previ-\nous hidden state and cell state of the LSTM unit. vd \u2208Rm,\nWd \u2208Rm\u00d72p and Ud \u2208Rm\u00d7m are parameters to learn. The\nbias terms here have been omitted for clarity. The attention\nweight \u03b2i\nt represents the importance of the i-th encoder hid-\nden state for the prediction. Since each encoder hidden state\nhi is mapped to a temporal component of the input, the atten-\ntion mechanism computes the context vectorct as a weighted\nsum of all the encoder hidden states {h1,h2,\u00b7\u00b7\u00b7 ,hT },\nct =\nT\u2211\ni=1\n\u03b2i\nthi. (14)\nNote that the context vector ct is distinct at each time step.\nOnce we get the weighted summed context vectors,\nwe can combine them with the given target series\n(y1,y2,\u00b7\u00b7\u00b7 ,yT\u22121):\n\u02dcyt\u22121 = \u02dcw\u22a4[yt\u22121; ct\u22121] +\u02dcb, (15)\nwhere [yt\u22121; ct\u22121] \u2208Rm+1 is a concatenation of the decoder\ninput yt\u22121 and the computed context vector ct\u22121. Parameters\n\u02dcw \u2208Rm+1 and \u02dcb \u2208R map the concatenation to the size the\ndecoder input. The newly computed \u02dcyt\u22121 can be used for the\nupdate of the decoder hidden state at time t:\ndt = f2(dt\u22121,\u02dcyt\u22121). (16)\nWe choose the nonlinear function f2 as an LSTM\nunit [Hochreiter and Schmidhuber, 1997 ], which has been\nwidely used in modeling long-term dependencies. Then dt\ncan be updated as:\nf\u2032\nt = \u03c3(W\u2032\nf [dt\u22121; \u02dcyt\u22121] +b\u2032\nf ) (17)", "mimetype": "text/plain", "start_char_idx": 2633, "end_char_idx": 5337, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "6fe602df-8a43-4a9d-9820-d1163691f80b": {"__data__": {"id_": "6fe602df-8a43-4a9d-9820-d1163691f80b", "embedding": null, "metadata": {"page_label": "4", "file_name": "1704.02971 (1).pdf", "file_path": "/Users/unman/ws/slow-productivity-ai/data/1704.02971 (1).pdf", "file_type": "application/pdf", "file_size": 488762, "creation_date": "2025-04-09", "last_modified_date": "2025-03-31"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "579982a0-8b10-4f70-a5ae-a732543de601", "node_type": "4", "metadata": {"page_label": "4", "file_name": "1704.02971 (1).pdf", "file_path": "/Users/unman/ws/slow-productivity-ai/data/1704.02971 (1).pdf", "file_type": "application/pdf", "file_size": 488762, "creation_date": "2025-04-09", "last_modified_date": "2025-03-31"}, "hash": "7200408dcd9595c8c11432d075c5c27ea76ad8001f6351047bbf5f26573efd7c", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "731c2bb4-4e3c-46d2-be43-68810f32dcfa", "node_type": "1", "metadata": {}, "hash": "46213b6ac7d57f6f70a38c5d4c54fd4d6f09b064db5294de0f9e8c1fcaade798", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Table 1: The statistics of two datasets.\nDataset driving\nseries\nsize\ntrain valid test\nSML 2010 16 3,200 400 537\nNASDAQ 100 Stock 81 35,100 2,730 2,730\ni\u2032\nt = \u03c3(W\u2032\ni[dt\u22121; \u02dcyt\u22121] +b\u2032\ni) (18)\no\u2032\nt = \u03c3(W\u2032\no[dt\u22121; \u02dcyt\u22121] +b\u2032\no) (19)\ns\u2032\nt = f\u2032\nt \u2299s\u2032\nt\u22121 + i\u2032\nt \u2299tanh(W\u2032\ns[dt\u22121; \u02dcyt\u22121] +b\u2032\ns) (20)\ndt = o\u2032\nt \u2299tanh(s\u2032\nt) (21)\nwhere [dt\u22121; \u02dcyt\u22121] \u2208Rp+1 is a concatenation of the previous\nhidden state dt\u22121 and the decoder input \u02dcyt\u22121. W\u2032\nf , W\u2032\ni, W\u2032\no,\nW\u2032\ns \u2208Rp\u00d7(p+1), and b\u2032\nf , b\u2032\ni, b\u2032\no, b\u2032\ns \u2208Rp are parameters to\nlearn. \u03c3and \u2299are a logistic sigmoid function and an element-\nwise multiplication, respectively.\nFor NARX modeling, we aim to use the DA-RNN to ap-\nproximate the function F so as to obtain an estimate of the\ncurrent output \u02c6yT with the observation of all inputs as well as\nprevious outputs. Speci\ufb01cally, \u02c6yT can be obtained with\n\u02c6yT = F(y1,\u00b7\u00b7\u00b7 ,yT\u22121,x1,\u00b7\u00b7\u00b7 ,xT )\n= v\u22a4\ny (Wy[dT ; cT ] +bw) +bv, (22)\nwhere [dT ; cT ] \u2208 Rp+m is a concatenation of the decoder\nhidden state and the context vector. The parameters Wy \u2208\nRp\u00d7(p+m) and bw \u2208Rp map the concatenation to the size of\nthe decoder hidden states. The linear function with weights\nvy \u2208Rp and bias bv \u2208R produces the \ufb01nal prediction result.\nTraining procedure\nWe use minibatch stochastic gradient descent (SGD) together\nwith the Adam optimizer [Kingma and Ba, 2014] to train the\nmodel. The size of the minibatch is 128. The learning rate\nstarts from 0.001 and is reduced by 10% after each 10000 iter-\nations. The proposed DA-RNN is smooth and differentiable,\nso the parameters can be learned by standard back propaga-\ntion with mean squared error as the objective function:\nO(yT ,\u02c6yT ) = 1\nN\nN\u2211\ni=1\n(\u02c6yi\nT \u2212yi\nT )2, (23)\nwhere N is the number of training samples. We implemented\nthe DA-RNN in the Tensor\ufb02ow framework [Abadi et al.,\n2015].\n3 Experiments\nIn this section, we \ufb01rst describe two datasets for empirical\nstudies. Then, we introduce the parameter settings of DA-\nRNN and the evaluation metrics. Finally, we compare the\nproposed DA-RNN against four different baseline methods,\ninterpret the input attention as well as the temporal attention\nof DA-RNN, and study its parameter sensitivity.\n3.1 Datasets and Setup\nTo test the performance of different methods for time series\nprediction, we use two different datasets as shown in Table 1.\nSML 2010 is a public dataset used for indoor temperature\nforecasting. This dataset is collected from a monitor system\nTime (minute)\n10 20 30 40 50 60\nNASDAQ 100\n4940\n4945\n4950\n4955\n4960 Ground Truth\nEncoder-Decoder\nTime (minute)\n10 20 30 40 50 60\nNASDAQ 100\n4940\n4945\n4950\n4955\n4960 Ground Truth\nAttention RNN\nTime (minute)\n10 20 30 40 50 60\nNASDAQ 100\n4940\n4945\n4950\n4955\n4960 Ground Truth\nDA-RNN\nFigure 2: NASDAQ 100 Index vs. Time. Encoder-Decoder (top) and\nAttention RNN (middle), are compared with DA-RNN (bottom).\nmounted in a domestic house.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2852, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "731c2bb4-4e3c-46d2-be43-68810f32dcfa": {"__data__": {"id_": "731c2bb4-4e3c-46d2-be43-68810f32dcfa", "embedding": null, "metadata": {"page_label": "4", "file_name": "1704.02971 (1).pdf", "file_path": "/Users/unman/ws/slow-productivity-ai/data/1704.02971 (1).pdf", "file_type": "application/pdf", "file_size": 488762, "creation_date": "2025-04-09", "last_modified_date": "2025-03-31"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "579982a0-8b10-4f70-a5ae-a732543de601", "node_type": "4", "metadata": {"page_label": "4", "file_name": "1704.02971 (1).pdf", "file_path": "/Users/unman/ws/slow-productivity-ai/data/1704.02971 (1).pdf", "file_type": "application/pdf", "file_size": 488762, "creation_date": "2025-04-09", "last_modified_date": "2025-03-31"}, "hash": "7200408dcd9595c8c11432d075c5c27ea76ad8001f6351047bbf5f26573efd7c", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "6fe602df-8a43-4a9d-9820-d1163691f80b", "node_type": "1", "metadata": {"page_label": "4", "file_name": "1704.02971 (1).pdf", "file_path": "/Users/unman/ws/slow-productivity-ai/data/1704.02971 (1).pdf", "file_type": "application/pdf", "file_size": 488762, "creation_date": "2025-04-09", "last_modified_date": "2025-03-31"}, "hash": "c7fd9e17c31a04cc172c99eebec25f080261eef968748df0ba15579d5bc823be", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "SML 2010 is a public dataset used for indoor temperature\nforecasting. This dataset is collected from a monitor system\nTime (minute)\n10 20 30 40 50 60\nNASDAQ 100\n4940\n4945\n4950\n4955\n4960 Ground Truth\nEncoder-Decoder\nTime (minute)\n10 20 30 40 50 60\nNASDAQ 100\n4940\n4945\n4950\n4955\n4960 Ground Truth\nAttention RNN\nTime (minute)\n10 20 30 40 50 60\nNASDAQ 100\n4940\n4945\n4950\n4955\n4960 Ground Truth\nDA-RNN\nFigure 2: NASDAQ 100 Index vs. Time. Encoder-Decoder (top) and\nAttention RNN (middle), are compared with DA-RNN (bottom).\nmounted in a domestic house. We use the room temperature\nas the target series and select 16 relevant driving series that\ncontain approximately 40 days of monitoring data. The data\nwas sampled every minute and was smoothed with 15 minute\nmeans. In our experiment, we use the \ufb01rst3200 data points as\nthe training set, the following400 data points as the validation\nset, and the last 537 data points as the test set.\nIn the NASDAQ 100 Stock dataset1, we collected the stock\nprices of 81 major corporations under NASDAQ 100, which\nare used as the driving time series. The index value of the\nNASDAQ 100 is used as the target series. The frequency of\nthe data collection is minute-by-minute. This data covers the\nperiod from July 26, 2016 to December 22, 2016, 105 days\nin total. Each day contains 390 data points from the opening\nto closing of the market except that there are 210 data points\non November 25 and 180 data points on December 22. In our\nexperiments, we use the \ufb01rst 35,100 data points as the training\nset and the following 2,730 data points as the validation set.\nThe last 2,730 data points are used as the test set. This dataset\nis publicly available and will be continuously enlarged to aid\nthe research in this direction.\n3.2 Parameter Settings and Evaluation Metrics\nThere are three parameters in the DA-RNN, i.e., the num-\nber of time steps in the window T, the size of hidden states\nfor the encoder m, and the size of hidden states for the de-\ncoder p. To determine the window size T, we conducted a\ngrid search over T \u2208{3,5,10,15,25}. The one ( T = 10)\nthat achieves the best performance over validation set is used\nfor test. For the size of hidden states for encoder ( m) and\ndecoder (p), we set m = p for simplicity and conduct grid\nsearch over m= p\u2208{16,32,64,128,256}. Those two ( i.e,\n1http://cseweb.ucsd.edu/\u223cyaq007/NASDAQ100 stock data.html", "mimetype": "text/plain", "start_char_idx": 2304, "end_char_idx": 4686, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "209a5652-7708-4486-a6b3-dba05c0fe6d0": {"__data__": {"id_": "209a5652-7708-4486-a6b3-dba05c0fe6d0", "embedding": null, "metadata": {"page_label": "5", "file_name": "1704.02971 (1).pdf", "file_path": "/Users/unman/ws/slow-productivity-ai/data/1704.02971 (1).pdf", "file_type": "application/pdf", "file_size": 488762, "creation_date": "2025-04-09", "last_modified_date": "2025-03-31"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "1cc7feb7-7921-44cb-81de-f04f84d3ee4f", "node_type": "4", "metadata": {"page_label": "5", "file_name": "1704.02971 (1).pdf", "file_path": "/Users/unman/ws/slow-productivity-ai/data/1704.02971 (1).pdf", "file_type": "application/pdf", "file_size": 488762, "creation_date": "2025-04-09", "last_modified_date": "2025-03-31"}, "hash": "8a919f03189503b4eb08323087ba98c74b903bbd07645f4f2e4d2dfbd2aecac8", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "d1e3b8f8-f6c1-4a57-a9d9-8d1389ab4a50", "node_type": "1", "metadata": {}, "hash": "90c22b2aff0247e41e59ce171ebf1c48c325d842c5439c50ca09c59d3bacdda7", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Table 2: Time series prediction results over the SML 2010 Dataset and NASDAQ 100 Stock Dataset (best performance displayed inboldface).\nThe size of encoder hidden states mand decoder hidden states pare set as m= p= 64and 128.\nModels\nSML 2010 Dataset NASDAQ 100 Stock Dataset\nMAE\n(\u00d710\u22122%)\nMAPE\n(\u00d710\u22122%)\nRMSE\n(\u00d710\u22122%) MAE MAPE\n(\u00d710\u22122%) RMSE\nARIMA [2011] 1.95 9.29 2.65 0.91 1.84 1.45\nNARX RNN [2008] 1.79\u00b10.07 8.64\u00b10.29 2.34\u00b10.08 0.75\u00b10.09 1.51 \u00b10.17 0.98\u00b10.10\nEncoder-Decoder (64) [2014b] 2.59\u00b10.07 12.1\u00b10.34 3.37\u00b10.07 0.97\u00b10.06 1.96\u00b10.12 1.27\u00b10.05\nEncoder-Decoder (128) [2014b] 1.91\u00b10.02 9.00\u00b10.10 2.52\u00b10.04 0.72 \u00b10.03 1.46\u00b10.06 1.00\u00b10.03\nAttention RNN (64) [2014] 1.78\u00b10.03 8.46\u00b10.09 2.32\u00b10.03 0.76\u00b10.08 1.54\u00b10.02 1.00\u00b10.09\nAttention RNN (128) [2014] 1.77\u00b10.02 8.45\u00b10.09 2.33\u00b10.03 0.71\u00b10.05 1.43\u00b10.09 0.96\u00b10.05\nInput-Attn-RNN (64) 1.88\u00b10.04 8.89\u00b10.19 2.50\u00b10.05 0.28\u00b10.02 0.57\u00b10.04 0.41\u00b10.03\nInput-Attn-RNN (128) 1.70\u00b10.03 8.09\u00b10.15 2.24\u00b10.03 0.26\u00b10.02 0.53\u00b10.03 0.39\u00b10.03\nDA-RNN (64) 1.53\u00b10.01 7.31\u00b10.05 2.02\u00b10.01 0.21\u00b10.002 0.43\u00b10.005 0.31\u00b10.003\nDA-RNN (128) 1.50\u00b10.01 7.14\u00b10.07 1.97\u00b10.01 0.22\u00b10.002 0.45\u00b10.005 0.33\u00b10.003\nm = p = 64, 128) that achieve the best performance over\nthe validation set are used for evaluation. For all the RNN\nbased approaches ( i.e., NARX RNN, Encoder-Decoder, At-\ntention RNN, Input-Attn-RNN and DA-RNN), we train them\n10 times and report their average performance and standard\ndeviations for comparison.\nTo measure the effectiveness of various methods for time\nseries prediction, we consider three different evaluation met-\nrics. Among them, root mean squared error (RMSE) [Plu-\ntowski et al., 1996] and mean absolute error (MAE) are two\nscale-dependent measures, and mean absolute percentage er-\nror (MAPE) is a scale-dependent measure. Speci\ufb01cally, as-\nsuming yt is the target at timetand \u02c6yt is the predicted value at\ntime t, RMSE is de\ufb01ned as RMSE =\n\u221a\n1\nN\n\u2211N\ni=1(yi\nt \u2212\u02c6yi\nt)2\nand MAE is denoted as MAE = 1\nN\n\u2211N\ni=1 |yi\nt \u2212 \u02c6yi\nt|.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1968, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "d1e3b8f8-f6c1-4a57-a9d9-8d1389ab4a50": {"__data__": {"id_": "d1e3b8f8-f6c1-4a57-a9d9-8d1389ab4a50", "embedding": null, "metadata": {"page_label": "5", "file_name": "1704.02971 (1).pdf", "file_path": "/Users/unman/ws/slow-productivity-ai/data/1704.02971 (1).pdf", "file_type": "application/pdf", "file_size": 488762, "creation_date": "2025-04-09", "last_modified_date": "2025-03-31"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "1cc7feb7-7921-44cb-81de-f04f84d3ee4f", "node_type": "4", "metadata": {"page_label": "5", "file_name": "1704.02971 (1).pdf", "file_path": "/Users/unman/ws/slow-productivity-ai/data/1704.02971 (1).pdf", "file_type": "application/pdf", "file_size": 488762, "creation_date": "2025-04-09", "last_modified_date": "2025-03-31"}, "hash": "8a919f03189503b4eb08323087ba98c74b903bbd07645f4f2e4d2dfbd2aecac8", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "209a5652-7708-4486-a6b3-dba05c0fe6d0", "node_type": "1", "metadata": {"page_label": "5", "file_name": "1704.02971 (1).pdf", "file_path": "/Users/unman/ws/slow-productivity-ai/data/1704.02971 (1).pdf", "file_type": "application/pdf", "file_size": 488762, "creation_date": "2025-04-09", "last_modified_date": "2025-03-31"}, "hash": "476885209fed7beb452832317cd3543ec8be43bc9c7756056fffded76c033578", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "aaee6495-da9a-40e4-b490-3277639432b6", "node_type": "1", "metadata": {}, "hash": "29c8805a7ade63ca616183e4b39f93adf573cfde9e6992bf9b5a52da510dc7b5", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "To measure the effectiveness of various methods for time\nseries prediction, we consider three different evaluation met-\nrics. Among them, root mean squared error (RMSE) [Plu-\ntowski et al., 1996] and mean absolute error (MAE) are two\nscale-dependent measures, and mean absolute percentage er-\nror (MAPE) is a scale-dependent measure. Speci\ufb01cally, as-\nsuming yt is the target at timetand \u02c6yt is the predicted value at\ntime t, RMSE is de\ufb01ned as RMSE =\n\u221a\n1\nN\n\u2211N\ni=1(yi\nt \u2212\u02c6yi\nt)2\nand MAE is denoted as MAE = 1\nN\n\u2211N\ni=1 |yi\nt \u2212 \u02c6yi\nt|.\nWhen comparing the prediction performance across different\ndatasets, mean absolute percentage error is popular because it\nmeasures the prediction deviation proportion in terms of the\ntrue values, i.e., MAPE = 1\nN\n\u2211N\ni=1 |yi\nt\u2212\u02c6yi\nt\nyi\nt\n|\u00d7100%.\n3.3 Results-I: Time Series Prediction\nTo demonstrate the effectiveness of the DA-RNN, we com-\npare it against 4 baseline methods. Among them, the au-\ntoregressive integrated moving average (ARIMA) model is a\ngeneralization of an autoregressive moving average (ARMA)\nmodel [Asteriou and Hall, 2011 ]. NARX recurrent neural\nnetwork (NARX RNN) is a classic method to address time se-\nries prediction [Diaconescu, 2008]. The encoder-decoder net-\nwork (Encoder-Decoder) [Cho et al., 2014b ] and attention-\nbased encoder-decoder network (Attention RNN) [Bahdanau\net al., 2014 ] were originally used for machine translation\ntasks, in which each time step of the decoder output should\nbe used to produce a probability distribution over the trans-\nlated word codebook. To perform time series prediction, we\nmodify these two approaches by changing the output to be\na single scalar value, and use a squared loss as the objective\nfunction (as we did for the DA-RNN). The input to these net-\nworks is no longer words or word representations, but the n\nscalar driving series of length T. Additionally, the decoder\nhas the additional input of the previous values of the target\nDriving Series\n20 40 60 80 100 120 140 160\nInput Attention Weights\n#10-3\n3\n4\n5\n6\n7\n8\nNASDAQ 100 Training Set\nDriving Series\n20 40 60 80 100 120 140 160\nInput Attention Weights\n#10-3\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\nNASDAQ 100 Test Set\nFigure 3: Plot of the input attention weights for DA-RNN from a\nsingle encoder time step. The \ufb01rst 81 weights are on 81 original\ndriving series and the last 81 weights are on 81 noisy driving series.\n(left) Input attention weights on NASDAQ100 training set. (right)\nInput attention weights on NASDAQ100 test set.\nseries as the given information.\nFurthermore, we show the effectiveness of DA-RNN via\nstep-by-step justi\ufb01cation. Speci\ufb01cally, we compare dual-\nstage attention-based recurrent neural network (DA-RNN)\nagainst the setting that only employs its input attention mech-\nanism (Input-Attn-RNN). For all RNN-based methods, the\nencoder takes n driving series of length T as the input and\nthe decoder takes the previous values of the target series as\nthe given information for fair comparison. The time series\nprediction results of DA-RNN and baseline methods over the\ntwo datasets are shown in Table 2.\nIn Table 2, we observe that the RMSE of ARIMA is gen-\nerally worse than RNN based approaches. This is because\nARIMA only considers the target series (y1,\u00b7\u00b7\u00b7 ,yt\u22121) and\nignores the driving series (x1,\u00b7\u00b7\u00b7 ,xt). For RNN based ap-\nproaches, the performance of NARX RNN and Encoder-\nDecoder are comparable. Attention RNN generally outper-\nforms Encoder-Decoder since it is capable to select relevant\nhidden states across all the time steps in the encoder.", "mimetype": "text/plain", "start_char_idx": 1437, "end_char_idx": 4956, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "aaee6495-da9a-40e4-b490-3277639432b6": {"__data__": {"id_": "aaee6495-da9a-40e4-b490-3277639432b6", "embedding": null, "metadata": {"page_label": "5", "file_name": "1704.02971 (1).pdf", "file_path": "/Users/unman/ws/slow-productivity-ai/data/1704.02971 (1).pdf", "file_type": "application/pdf", "file_size": 488762, "creation_date": "2025-04-09", "last_modified_date": "2025-03-31"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "1cc7feb7-7921-44cb-81de-f04f84d3ee4f", "node_type": "4", "metadata": {"page_label": "5", "file_name": "1704.02971 (1).pdf", "file_path": "/Users/unman/ws/slow-productivity-ai/data/1704.02971 (1).pdf", "file_type": "application/pdf", "file_size": 488762, "creation_date": "2025-04-09", "last_modified_date": "2025-03-31"}, "hash": "8a919f03189503b4eb08323087ba98c74b903bbd07645f4f2e4d2dfbd2aecac8", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "d1e3b8f8-f6c1-4a57-a9d9-8d1389ab4a50", "node_type": "1", "metadata": {"page_label": "5", "file_name": "1704.02971 (1).pdf", "file_path": "/Users/unman/ws/slow-productivity-ai/data/1704.02971 (1).pdf", "file_type": "application/pdf", "file_size": 488762, "creation_date": "2025-04-09", "last_modified_date": "2025-03-31"}, "hash": "cc849ba946d0b30118c41944ac476f18f32dd383099834ce18aefa17cc43ebe8", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "For all RNN-based methods, the\nencoder takes n driving series of length T as the input and\nthe decoder takes the previous values of the target series as\nthe given information for fair comparison. The time series\nprediction results of DA-RNN and baseline methods over the\ntwo datasets are shown in Table 2.\nIn Table 2, we observe that the RMSE of ARIMA is gen-\nerally worse than RNN based approaches. This is because\nARIMA only considers the target series (y1,\u00b7\u00b7\u00b7 ,yt\u22121) and\nignores the driving series (x1,\u00b7\u00b7\u00b7 ,xt). For RNN based ap-\nproaches, the performance of NARX RNN and Encoder-\nDecoder are comparable. Attention RNN generally outper-\nforms Encoder-Decoder since it is capable to select relevant\nhidden states across all the time steps in the encoder. Within\nDA-RNN, the input attention RNN (Input-Attn-RNN (128))\nconsistently outperforms Encoder-Decoder as well as Atten-\ntion RNN. This suggests that adaptively extracting driving se-\nries can provide more reliable input features to make accurate\npredictions. With integration of the input attention mech-\nanism as well as temporal attention mechanism, our DA-\nRNN achieves the bestMAE, MAPE, and RMSE across two", "mimetype": "text/plain", "start_char_idx": 4200, "end_char_idx": 5369, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "2cec6d4d-f10f-4436-9f5a-efc5b07d1b00": {"__data__": {"id_": "2cec6d4d-f10f-4436-9f5a-efc5b07d1b00", "embedding": null, "metadata": {"page_label": "6", "file_name": "1704.02971 (1).pdf", "file_path": "/Users/unman/ws/slow-productivity-ai/data/1704.02971 (1).pdf", "file_type": "application/pdf", "file_size": 488762, "creation_date": "2025-04-09", "last_modified_date": "2025-03-31"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "9205f1a4-d34c-4d87-ab03-56ed03e9a1c6", "node_type": "4", "metadata": {"page_label": "6", "file_name": "1704.02971 (1).pdf", "file_path": "/Users/unman/ws/slow-productivity-ai/data/1704.02971 (1).pdf", "file_type": "application/pdf", "file_size": 488762, "creation_date": "2025-04-09", "last_modified_date": "2025-03-31"}, "hash": "3ad250e64a5cc59933353c0e2ae64afe3a90f50ac6e78d9349ec98bdd8cf005b", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "e1bbed59-a25d-46f0-b67e-f67925f06c5f", "node_type": "1", "metadata": {}, "hash": "5e30294f917669b6942dc84cebabde5a68b1897cae6044ed35e74c94f2665397", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Length of time steps (T)\n3 5 10 15 25\nRMSE\n0.018\n0.02\n0.022\n0.024\n0.026\n0.028\n0.03\n0.032 SML 2010\nInput-Attn-RNN\nDA-RNN\nLength of time steps (T)\n3 5 10 15 25\nRMSE\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1 NASDAQ 100 Stock\nInput-Attn-RNN\nDA-RNN\nSize of Hidden States\n16 32 64 128 256\nRMSE\n0.2\n0.4\n0.6\n0.8\n1\n1.2\n1.4\n1.6 NASDAQ 100 Stock\nInput-Attn-RNN\nDA-RNN\nSize of Hidden States\n16 32 64 128 256\nRMSE\n0.018\n0.02\n0.022\n0.024\n0.026\n0.028 SML 2010\nInput-Attn-RNN\nDA-RNN\nFigure 4: RMSE vs. length of time steps T over SML 2010 (left)\nand NASDAQ 100 Stock (right).\ndatasets since it not only uses an input attention mechanism\nto extract relevant driving series, but also employs a temporal\nattention mechanism to select relevant hidden features across\nall time steps.\nFor visual comparison, we show the prediction result of\nEncoder-Decoder (m= p= 128), Attention RNN (m= p=\n128) and DA-RNN ( m = p = 64) over the NASDAQ 100\nStock dataset in Figure 2. We observe that DA-RNN gener-\nally \ufb01ts the ground truth much better than Encoder-Decoder\nand Attention RNN.\n3.4 Results-II: Interpretation\nTo study the effectiveness of the input attention mechanism\nwithin DA-RNN, we test it with noisy driving (exogenous)\nseries as the input. Speci\ufb01cally, within NASDAQ 100 Stock\ndataset, we generate 81 additional noisy driving series by\nrandomly permuting the original 81 driving series. Then,\nwe put these 81 noisy driving series together with the 81\noriginal driving series as the input and test the effective-\nness of DA-RNN. When the length of time steps T is 10\nand the size of hidden states is m = p = 128, DA-RNN\nachieves MAE: 0.28 \u00b10.007, MAPE: (0.56 \u00b10.01)\u00d710\u22122\nand RMSE: 0.42 \u00b10.009, which are comparable to its per-\nformance in Table 2. This indicates that DA-RNN is robust\nto noisy inputs.\nTo further investigate the input attention mechanism, we\nplot the input attention weights of DA-RNN for the 162 in-\nput driving series (the \ufb01rst 81 are original and the last 81\nare noisy) in Figure 3. The plotted attention weights in Fig-\nure 3 are taken from a single encoder time step and similar\npatterns can also be observed for other time steps. We \ufb01nd\nthat the input attention mechanism can automatically assign\nlarger weights for the 81 original driving series and smaller\nweights for the 81 noisy driving series in an online fashion\nusing the activation of the input attention network to scale\nthese weights. This demonstrates that input attention mecha-\nnism can aid DA-RNN to select relevant input driving series\nand suppress noisy input driving series.\nTo investigate the effectiveness of the temporal attention\nmechanism within DA-RNN, we compare DA-RNN to Input-\nAttn-RNN when the length of time steps T varies from 3,\n5, 10, 15, to 25. The detailed results over two datasets are\nshown in Figure 4. We observe that whenT is relatively large,\nDA-RNN can signi\ufb01cantly outperform Input-Attn-RNN. This\nsuggests that temporal attention mechanism can capture long-\nterm dependencies by selecting relevant encoder hidden states\nacross all the time steps.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3032, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "e1bbed59-a25d-46f0-b67e-f67925f06c5f": {"__data__": {"id_": "e1bbed59-a25d-46f0-b67e-f67925f06c5f", "embedding": null, "metadata": {"page_label": "6", "file_name": "1704.02971 (1).pdf", "file_path": "/Users/unman/ws/slow-productivity-ai/data/1704.02971 (1).pdf", "file_type": "application/pdf", "file_size": 488762, "creation_date": "2025-04-09", "last_modified_date": "2025-03-31"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "9205f1a4-d34c-4d87-ab03-56ed03e9a1c6", "node_type": "4", "metadata": {"page_label": "6", "file_name": "1704.02971 (1).pdf", "file_path": "/Users/unman/ws/slow-productivity-ai/data/1704.02971 (1).pdf", "file_type": "application/pdf", "file_size": 488762, "creation_date": "2025-04-09", "last_modified_date": "2025-03-31"}, "hash": "3ad250e64a5cc59933353c0e2ae64afe3a90f50ac6e78d9349ec98bdd8cf005b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "2cec6d4d-f10f-4436-9f5a-efc5b07d1b00", "node_type": "1", "metadata": {"page_label": "6", "file_name": "1704.02971 (1).pdf", "file_path": "/Users/unman/ws/slow-productivity-ai/data/1704.02971 (1).pdf", "file_type": "application/pdf", "file_size": 488762, "creation_date": "2025-04-09", "last_modified_date": "2025-03-31"}, "hash": "b93a9f5cd7f6b855f43f640a67fa47d042276037aff64353cc25d7d2efb01fdd", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "27d87978-388f-41c9-8f2d-586ae30c1922", "node_type": "1", "metadata": {}, "hash": "1b452ff6f79d9c896e3e989c38bbb73844d8bd4d30579030216697b843352977", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "This demonstrates that input attention mecha-\nnism can aid DA-RNN to select relevant input driving series\nand suppress noisy input driving series.\nTo investigate the effectiveness of the temporal attention\nmechanism within DA-RNN, we compare DA-RNN to Input-\nAttn-RNN when the length of time steps T varies from 3,\n5, 10, 15, to 25. The detailed results over two datasets are\nshown in Figure 4. We observe that whenT is relatively large,\nDA-RNN can signi\ufb01cantly outperform Input-Attn-RNN. This\nsuggests that temporal attention mechanism can capture long-\nterm dependencies by selecting relevant encoder hidden states\nacross all the time steps.\nLength of time steps (T)\n3 5 10 15 25\nRMSE\n0.018\n0.02\n0.022\n0.024\n0.026\n0.028\n0.03\n0.032 SML 2010\nInput-Attn-RNN\nDA-RNN\nLength of time steps (T)\n3 5 10 15 25\nRMSE\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1 NASDAQ 100 Stock\nInput-Attn-RNN\nDA-RNN\nSize of Hidden States\n16 32 64 128 256\nRMSE\n0.2\n0.4\n0.6\n0.8\n1\n1.2\n1.4\n1.6 NASDAQ 100 Stock\nInput-Attn-RNN\nDA-RNN\nSize of Hidden States\n16 32 64 128 256\nRMSE\n0.018\n0.02\n0.022\n0.024\n0.026\n0.028 SML 2010\nInput-Attn-RNN\nDA-RNN\nFigure 5: RMSE vs. size of hidden states of encoder/decoder over\nSML 2010 (left) and NASDAQ 100 Stock (right).\n3.5 Results-III: Parameter Sensitivity\nWe study the sensitivity of DA-RNN with respect to its pa-\nrameters, i.e., the length of time steps T and the size of hid-\nden states for encoder m (decoder p). When we vary T or\nm(p), we keep the others \ufb01xed. By setting m = p = 128,\nwe plot the RMSE versus different lengths of time steps in\nthe window T in Figure 4. It is easily observed that the\nperformance of DA-RNN and Input-Attn-RNN will be worse\nwhen the length of time steps is too short or too long while\nDA-RNN is relatively more robust than Input-Attn-RNN. By\nsetting T = 10, we also plot the RMSE versus different\nsizes of hidden states for encoder and decoder ( m = p \u2208\n{16,32,64,128,256}) in Figure 5. We notice that DA-RNN\nusually achieves the best performance when m = p = 64or\n128. Moreover, we can also conclude that DA-RNN is more\nrobust to parameters than Input-Attn-RNN.\n4 Conclusion\nIn this paper, we proposed a novel dual-stage attention-based\nrecurrent neural network (DA-RNN), which consists of an en-\ncoder with an input attention mechanism and a decoder with\na temporal attention mechanism. The newly introduced in-\nput attention mechanism can adaptively select the relevant\ndriving series. The temporal attention mechanism can nat-\nurally capture the long-range temporal information of the en-\ncoded inputs. Based upon these two attention mechanisms,\nthe DA-RNN can not only adaptively select the most relevant\ninput features, but can also capture the long-term temporal\ndependencies of a time series appropriately. Extensive exper-\niments on the SML 2010 dataset and the NASDAQ 100 Stock\ndataset demonstrated that our proposed DA-RNN can outper-\nform state-of-the-art methods for time series prediction.\nThe proposed dual-stage attention-based recurrent neural\nnetwork (DA-RNN) not only can be used for time series pre-\ndiction, but also has the potential to serve as a general feature\nlearning tool in computer vision tasks [Pu et al., 2016; Qin et\nal., 2015]. In the future, we are going to employ DA-RNN\nto perform ranking and binary coding [Song et al., 2015;\nSong et al., 2016].", "mimetype": "text/plain", "start_char_idx": 2389, "end_char_idx": 5702, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "27d87978-388f-41c9-8f2d-586ae30c1922": {"__data__": {"id_": "27d87978-388f-41c9-8f2d-586ae30c1922", "embedding": null, "metadata": {"page_label": "6", "file_name": "1704.02971 (1).pdf", "file_path": "/Users/unman/ws/slow-productivity-ai/data/1704.02971 (1).pdf", "file_type": "application/pdf", "file_size": 488762, "creation_date": "2025-04-09", "last_modified_date": "2025-03-31"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "9205f1a4-d34c-4d87-ab03-56ed03e9a1c6", "node_type": "4", "metadata": {"page_label": "6", "file_name": "1704.02971 (1).pdf", "file_path": "/Users/unman/ws/slow-productivity-ai/data/1704.02971 (1).pdf", "file_type": "application/pdf", "file_size": 488762, "creation_date": "2025-04-09", "last_modified_date": "2025-03-31"}, "hash": "3ad250e64a5cc59933353c0e2ae64afe3a90f50ac6e78d9349ec98bdd8cf005b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e1bbed59-a25d-46f0-b67e-f67925f06c5f", "node_type": "1", "metadata": {"page_label": "6", "file_name": "1704.02971 (1).pdf", "file_path": "/Users/unman/ws/slow-productivity-ai/data/1704.02971 (1).pdf", "file_type": "application/pdf", "file_size": 488762, "creation_date": "2025-04-09", "last_modified_date": "2025-03-31"}, "hash": "a2abbedd7338eb131b29f0762635d1d13ade071b06ca337fe07e1145a88fb703", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Based upon these two attention mechanisms,\nthe DA-RNN can not only adaptively select the most relevant\ninput features, but can also capture the long-term temporal\ndependencies of a time series appropriately. Extensive exper-\niments on the SML 2010 dataset and the NASDAQ 100 Stock\ndataset demonstrated that our proposed DA-RNN can outper-\nform state-of-the-art methods for time series prediction.\nThe proposed dual-stage attention-based recurrent neural\nnetwork (DA-RNN) not only can be used for time series pre-\ndiction, but also has the potential to serve as a general feature\nlearning tool in computer vision tasks [Pu et al., 2016; Qin et\nal., 2015]. In the future, we are going to employ DA-RNN\nto perform ranking and binary coding [Song et al., 2015;\nSong et al., 2016].\nAcknowledgments\nGWC is supported in part by NSF cooperative agreement\nSMA 1041755 to the Temporal Dynamics of Learning Cen-\nter, and a gift from Hewlett Packard. GWC and YQ were also\npartially supported by Guangzhou Science and Technology\nPlanning Project (Grant No. 201704030051).", "mimetype": "text/plain", "start_char_idx": 4926, "end_char_idx": 5984, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "51c38d12-84b8-48c2-9d47-2a65540b7327": {"__data__": {"id_": "51c38d12-84b8-48c2-9d47-2a65540b7327", "embedding": null, "metadata": {"page_label": "7", "file_name": "1704.02971 (1).pdf", "file_path": "/Users/unman/ws/slow-productivity-ai/data/1704.02971 (1).pdf", "file_type": "application/pdf", "file_size": 488762, "creation_date": "2025-04-09", "last_modified_date": "2025-03-31"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2f8534ef-48a1-4d6c-bfc3-a111f10fda9c", "node_type": "4", "metadata": {"page_label": "7", "file_name": "1704.02971 (1).pdf", "file_path": "/Users/unman/ws/slow-productivity-ai/data/1704.02971 (1).pdf", "file_type": "application/pdf", "file_size": 488762, "creation_date": "2025-04-09", "last_modified_date": "2025-03-31"}, "hash": "c8c05ef501dc67e22dd58d714a140db0c0c86eb4cc35967f309db50d9874b2ec", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "6e5c8941-bfb7-40ae-9c39-e95199b5a90b", "node_type": "1", "metadata": {}, "hash": "0a94170ae52faf1d06681be96ad077126bbc5a66e1d5fdf97e874d96c2526535", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "References\n[Abadi et al., 2015] Mart\u0131n Abadi, Ashish Agarwal, Paul Barham,\nEugene Brevdo, Zhifeng Chen, Craig Citro, Greg S Corrado,\nAndy Davis, Jeffrey Dean, Matthieu Devin, et al. Tensor\ufb02ow:\nLarge-scale machine learning on heterogeneous systems. 2015.\n[Asteriou and Hall, 2011] Dimitros Asteriou and Stephen G Hall.\nArima models and the box-jenkins methodology.Applied Econo-\nmetrics, 2(2):265\u2013286, 2011.\n[Bahdanau et al., 2014] Dzmitry Bahdanau, Kyunghyun Cho, and\nYoshua Bengio. Neural machine translation by jointly learning\nto align and translate. arXiv:1409.0473, 2014.\n[Bengio et al., 1994] Yoshua Bengio, Patrice Simard, and Paolo\nFrasconi. Learning long-term dependencies with gradient descent\nis dif\ufb01cult. IEEE Transactions on Neural Networks, 5(2):157\u2013\n166, 1994.\n[Bouchachia and Bouchachia, 2008] Abdelhamid Bouchachia and\nSaliha Bouchachia. Ensemble learning for time series prediction.\nIn Proceedings of the 1st International Workshop on Nonlinear\nDynamics and Synchronization, 2008.\n[Brockwell and Davis, 2009] Peter J. Brockwell and Richard A\nDavis. Time Series: Theory and Methods (2nd ed.). Springer,\n2009.\n[Chakraborty et al., 2012] Prithwish Chakraborty, Manish Mar-\nwah, Martin F Arlitt, and Naren Ramakrishnan. Fine-grained\nphotovoltaic output prediction using a bayesian ensemble. In\nAAAI, 2012.\n[Chen et al., 2008] S. Chen, X. X. Wang, and C. J. Harris. Narx-\nbased nonlinear system identi\ufb01cation using orthogonal least\nsquares basis hunting. IEEE Transactions on Control Systems\nTechnology, 16(1):78\u201384, 2008.\n[Cho et al., 2014a] Kyunghyun Cho, Bart Van Merri \u00a8enboer,\nDzmitry Bahdanau, and Yoshua Bengio. On the properties\nof neural machine translation: Encoder-decoder approaches.\narXiv:1409.1259, 2014.\n[Cho et al., 2014b] Kyunghyun Cho, Bart Van Merri\u00a8enboer, Caglar\nGulcehre, Dzmitry Bahdanau, Fethi Bougares, Holger Schwenk,\nand Yoshua Bengio. Learning phrase representations us-\ning rnn encoder-decoder for statistical machine translation.\narXiv:1406.1078, 2014.\n[Diaconescu, 2008] Eugen Diaconescu. The use of NARX neural\nnetworks to predict chaotic time series. WSEA Transactions on\nComputer Research, 3(3), 2008.\n[Elman, 1991] Jeffrey L Elman. Distributed representations, simple\nrecurrent networks, and grammatical structure. Machine learn-\ning, 7(2-3):195\u2013225, 1991.\n[Frigola and Rasmussen, 2014] R. Frigola and C. E. Rasmussen.\nIntegrated pre-processing for bayesian nonlinear system identi\ufb01-\ncation with gaussian processes. In IEEE Conference on Decision\nand Control, pages 552\u2013560, 2014.\n[Gao and Er, 2005] Yang Gao and Meng Joo Er. Narmax time se-\nries model prediction: feedforward and recurrent fuzzy neural\nnetwork approaches. Fuzzy Sets and Systems, 150(2):331\u2013350,\n2005.\n[Graves et al., 2013] Alex Graves, Abdel-rahman Mohamed, and\nGeoffrey Hinton. Speech recognition with deep recurrent neu-\nral networks. In ICASSP, pages 6645\u20136649, 2013.\n[Hochreiter and Schmidhuber, 1997] Sepp Hochreiter and J \u00a8urgen\nSchmidhuber. Long short-term memory.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2988, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "6e5c8941-bfb7-40ae-9c39-e95199b5a90b": {"__data__": {"id_": "6e5c8941-bfb7-40ae-9c39-e95199b5a90b", "embedding": null, "metadata": {"page_label": "7", "file_name": "1704.02971 (1).pdf", "file_path": "/Users/unman/ws/slow-productivity-ai/data/1704.02971 (1).pdf", "file_type": "application/pdf", "file_size": 488762, "creation_date": "2025-04-09", "last_modified_date": "2025-03-31"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2f8534ef-48a1-4d6c-bfc3-a111f10fda9c", "node_type": "4", "metadata": {"page_label": "7", "file_name": "1704.02971 (1).pdf", "file_path": "/Users/unman/ws/slow-productivity-ai/data/1704.02971 (1).pdf", "file_type": "application/pdf", "file_size": 488762, "creation_date": "2025-04-09", "last_modified_date": "2025-03-31"}, "hash": "c8c05ef501dc67e22dd58d714a140db0c0c86eb4cc35967f309db50d9874b2ec", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "51c38d12-84b8-48c2-9d47-2a65540b7327", "node_type": "1", "metadata": {"page_label": "7", "file_name": "1704.02971 (1).pdf", "file_path": "/Users/unman/ws/slow-productivity-ai/data/1704.02971 (1).pdf", "file_type": "application/pdf", "file_size": 488762, "creation_date": "2025-04-09", "last_modified_date": "2025-03-31"}, "hash": "603daa0f7b79691a649bc96559bf30e05e3298dd40b9091aefffaebe9b5091ae", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "76568e15-15f6-4d8b-af35-ee64625316ff", "node_type": "1", "metadata": {}, "hash": "6d2334e51a07bfd60faa139ad7dd7fddec1560a3cf50d46a87aeb7396d2ae211", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Integrated pre-processing for bayesian nonlinear system identi\ufb01-\ncation with gaussian processes. In IEEE Conference on Decision\nand Control, pages 552\u2013560, 2014.\n[Gao and Er, 2005] Yang Gao and Meng Joo Er. Narmax time se-\nries model prediction: feedforward and recurrent fuzzy neural\nnetwork approaches. Fuzzy Sets and Systems, 150(2):331\u2013350,\n2005.\n[Graves et al., 2013] Alex Graves, Abdel-rahman Mohamed, and\nGeoffrey Hinton. Speech recognition with deep recurrent neu-\nral networks. In ICASSP, pages 6645\u20136649, 2013.\n[Hochreiter and Schmidhuber, 1997] Sepp Hochreiter and J \u00a8urgen\nSchmidhuber. Long short-term memory. Neural Computation,\n9(8):1735\u20131780, 1997.\n[H\u00a8ubner et al., 2010] Ronald H\u00a8ubner, Marco Steinhauser, and Car-\nola Lehle. A dual-stage two-phase model of selective attention.\nPsychological Review, 117(3):759\u2013784, 2010.\n[Kalchbrenner and Blunsom, 2013] Nal Kalchbrenner and Phil\nBlunsom. Recurrent continuous translation models. In EMNLP,\nvolume 3, pages 413\u2013422, 2013.\n[Karpathy and Li, 2015] Andrej Karpathy and Fei-Fei Li. Deep\nvisual-semantic alignments for generating image descriptions. In\nCVPR, pages 3128\u20133137, 2015.\n[Kingma and Ba, 2014] Diederik Kingma and Jimmy Ba. Adam: A\nmethod for stochastic optimization. arXiv:1412.6980, 2014.\n[Lin et al., 1996] Tsungnan Lin, Bill G. Horne, Peter Tino, and\nC. Lee Giles. Learning long-term dependencies in NARX recur-\nrent neural networks. IEEE Transactions on Neural Networks,\n7(6):1329\u20131338, 1996.\n[Liu and Hauskrecht, 2015] Zitao Liu and Milos Hauskrecht. A\nregularized linear dynamical system framework for multivariate\ntime series analysis. In AAAI, pages 1798\u20131805, 2015.\n[Plutowski et al., 1996] Mark Plutowski, Garrison Cottrell, and\nHalbert White. Experience with selecting exemplars from clean\ndata. Neural Networks, 9(2):273\u2013294, 1996.\n[Pu et al., 2016] Yunchen Pu, Martin Renqiang Min, Zhe Gan, and\nLawrence Carin. Adaptive feature abstraction for translating\nvideo to language. arXiv preprint arXiv:1611.07837, 2016.\n[Qin et al., 2015] Yao Qin, Huchuan Lu, Yiqun Xu, and He Wang.\nSaliency detection via cellular automata. In CVPR, pages 110\u2013\n119, 2015.\n[Rumelhart et al., 1986] David E Rumelhart, Geoffrey E Hinton,\nand Ronald J Williams. Learning representations by back-\npropagating errors. Nature, 323(9):533\u2013536, 1986.\n[Song et al., 2015] Dongjin Song, Wei Liu, Rongrong Ji, David A\nMeyer, and John R Smith. Top rank supervised binary coding for\nvisual search. In ICCV, pages 1922\u20131930, 2015.\n[Song et al., 2016] Dongjin Song, Wei Liu, and David A Meyer.\nFast structural binary coding. In IJCAI, pages 2018\u20132024, 2016.\n[Sutskever et al., 2014] Ilya Sutskever, Oriol Vinyals, and Quoc V\nLe. Sequence to sequence learning with neural networks. In\nNIPS, pages 3104\u20133112, 2014.\n[Werbos, 1990] Paul J Werbos. Backpropagation through time:\nwhat it does and how to do it. Proceedings of the IEEE,\n78(10):1550\u20131560, 1990.", "mimetype": "text/plain", "start_char_idx": 2367, "end_char_idx": 5267, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "76568e15-15f6-4d8b-af35-ee64625316ff": {"__data__": {"id_": "76568e15-15f6-4d8b-af35-ee64625316ff", "embedding": null, "metadata": {"page_label": "7", "file_name": "1704.02971 (1).pdf", "file_path": "/Users/unman/ws/slow-productivity-ai/data/1704.02971 (1).pdf", "file_type": "application/pdf", "file_size": 488762, "creation_date": "2025-04-09", "last_modified_date": "2025-03-31"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2f8534ef-48a1-4d6c-bfc3-a111f10fda9c", "node_type": "4", "metadata": {"page_label": "7", "file_name": "1704.02971 (1).pdf", "file_path": "/Users/unman/ws/slow-productivity-ai/data/1704.02971 (1).pdf", "file_type": "application/pdf", "file_size": 488762, "creation_date": "2025-04-09", "last_modified_date": "2025-03-31"}, "hash": "c8c05ef501dc67e22dd58d714a140db0c0c86eb4cc35967f309db50d9874b2ec", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "6e5c8941-bfb7-40ae-9c39-e95199b5a90b", "node_type": "1", "metadata": {"page_label": "7", "file_name": "1704.02971 (1).pdf", "file_path": "/Users/unman/ws/slow-productivity-ai/data/1704.02971 (1).pdf", "file_type": "application/pdf", "file_size": 488762, "creation_date": "2025-04-09", "last_modified_date": "2025-03-31"}, "hash": "6b4fc1ce19cce638a64ff0f751fc97a089edd404e8513ca720a7866fbd4a4976", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Top rank supervised binary coding for\nvisual search. In ICCV, pages 1922\u20131930, 2015.\n[Song et al., 2016] Dongjin Song, Wei Liu, and David A Meyer.\nFast structural binary coding. In IJCAI, pages 2018\u20132024, 2016.\n[Sutskever et al., 2014] Ilya Sutskever, Oriol Vinyals, and Quoc V\nLe. Sequence to sequence learning with neural networks. In\nNIPS, pages 3104\u20133112, 2014.\n[Werbos, 1990] Paul J Werbos. Backpropagation through time:\nwhat it does and how to do it. Proceedings of the IEEE,\n78(10):1550\u20131560, 1990.\n[Whittle, 1951] P. Whittle. Hypothesis Testing in Time Series Anal-\nysis. PhD thesis, 1951.\n[Wu et al., 2013] Yue Wu, Jos \u00b4e Miguel Hern \u00b4andez-Lobato, and\nZoubin Ghahramani. Dynamic covariance models for multivari-\nate \ufb01nancial time series. In ICML, pages 558\u2013566, 2013.\n[Xu et al., 2015] Kelvin Xu, Jimmy Ba, Ryan Kiros, Kyunghyun\nCho, Aaron C Courville, Ruslan Salakhutdinov, Richard S\nZemel, and Yoshua Bengio. Show, attend and tell: Neural image\ncaption generation with visual attention. In ICML, volume 14,\npages 77\u201381, 2015.\n[Yan et al., 2013] Linjun Yan, Ahmed Elgamal, and Garrison W.\nCottrell. Substructure vibration NARX neural network approach\nfor statistical damage inference. Journal of Engineering Mechan-\nics, 139:737\u2013747, 2013.\n[Yang et al., 2016] Zichao Yang, Diyi Yang, Chris Dyer, Xiaodong\nHe, Alex Smola, and Eduard Hovy. Hierarchical attention net-\nworks for document classi\ufb01cation. In NAACL, 2016.", "mimetype": "text/plain", "start_char_idx": 4762, "end_char_idx": 6188, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "614850f2-eb37-4e8b-aef4-e204324ae9b5": {"__data__": {"id_": "614850f2-eb37-4e8b-aef4-e204324ae9b5", "embedding": null, "metadata": {"page_label": "1", "file_name": "2022-04-05 March comments on V3 flag channels.pdf", "file_path": "/Users/unman/ws/slow-productivity-ai/data/2022-04-05 March comments on V3 flag channels.pdf", "file_type": "application/pdf", "file_size": 3639696, "creation_date": "2025-04-09", "last_modified_date": "2025-03-31"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "c9131b7e-b636-454e-805e-90581068de64", "node_type": "4", "metadata": {"page_label": "1", "file_name": "2022-04-05 March comments on V3 flag channels.pdf", "file_path": "/Users/unman/ws/slow-productivity-ai/data/2022-04-05 March comments on V3 flag channels.pdf", "file_type": "application/pdf", "file_size": 3639696, "creation_date": "2025-04-09", "last_modified_date": "2025-03-31"}, "hash": "f5c646d1391780872a4d19be9c2084a91ffc83bcbf21bf67994eb4c5bc2b3864", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 0, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "4745628e-ab0f-4ab6-870d-b23b79b8e616": {"__data__": {"id_": "4745628e-ab0f-4ab6-870d-b23b79b8e616", "embedding": null, "metadata": {"page_label": "2", "file_name": "2022-04-05 March comments on V3 flag channels.pdf", "file_path": "/Users/unman/ws/slow-productivity-ai/data/2022-04-05 March comments on V3 flag channels.pdf", "file_type": "application/pdf", "file_size": 3639696, "creation_date": "2025-04-09", "last_modified_date": "2025-03-31"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2ec865cf-e9fe-47a2-8e3e-1061a24bab5e", "node_type": "4", "metadata": {"page_label": "2", "file_name": "2022-04-05 March comments on V3 flag channels.pdf", "file_path": "/Users/unman/ws/slow-productivity-ai/data/2022-04-05 March comments on V3 flag channels.pdf", "file_type": "application/pdf", "file_size": 3639696, "creation_date": "2025-04-09", "last_modified_date": "2025-03-31"}, "hash": "0333e2d64631586e89736bc261359c91ef21741370ccac84bf36d361147fc210", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 0, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "8892770e-ead6-4bb6-ae8f-02ffb2b4b571": {"__data__": {"id_": "8892770e-ead6-4bb6-ae8f-02ffb2b4b571", "embedding": null, "metadata": {"page_label": "3", "file_name": "2022-04-05 March comments on V3 flag channels.pdf", "file_path": "/Users/unman/ws/slow-productivity-ai/data/2022-04-05 March comments on V3 flag channels.pdf", "file_type": "application/pdf", "file_size": 3639696, "creation_date": "2025-04-09", "last_modified_date": "2025-03-31"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "f5b274b5-39d7-4b1f-97a8-39fdd91a769f", "node_type": "4", "metadata": {"page_label": "3", "file_name": "2022-04-05 March comments on V3 flag channels.pdf", "file_path": "/Users/unman/ws/slow-productivity-ai/data/2022-04-05 March comments on V3 flag channels.pdf", "file_type": "application/pdf", "file_size": 3639696, "creation_date": "2025-04-09", "last_modified_date": "2025-03-31"}, "hash": "75a67444d2aa32f9687ba06e2a775728e04c705dcf6a0698b427dd69559d59dd", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 0, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "e3db68b8-f175-4ef7-a276-f8ddfec754e5": {"__data__": {"id_": "e3db68b8-f175-4ef7-a276-f8ddfec754e5", "embedding": null, "metadata": {"page_label": "4", "file_name": "2022-04-05 March comments on V3 flag channels.pdf", "file_path": "/Users/unman/ws/slow-productivity-ai/data/2022-04-05 March comments on V3 flag channels.pdf", "file_type": "application/pdf", "file_size": 3639696, "creation_date": "2025-04-09", "last_modified_date": "2025-03-31"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2cfb4c26-85e2-4a90-952a-68981772a34f", "node_type": "4", "metadata": {"page_label": "4", "file_name": "2022-04-05 March comments on V3 flag channels.pdf", "file_path": "/Users/unman/ws/slow-productivity-ai/data/2022-04-05 March comments on V3 flag channels.pdf", "file_type": "application/pdf", "file_size": 3639696, "creation_date": "2025-04-09", "last_modified_date": "2025-03-31"}, "hash": "68ab432ce07192fe22771a6ca450a469007375b096f21dcdbf41a9de85b062b3", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 0, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "1e572200-cde2-4669-a957-cf3993646f6d": {"__data__": {"id_": "1e572200-cde2-4669-a957-cf3993646f6d", "embedding": null, "metadata": {"page_label": "5", "file_name": "2022-04-05 March comments on V3 flag channels.pdf", "file_path": "/Users/unman/ws/slow-productivity-ai/data/2022-04-05 March comments on V3 flag channels.pdf", "file_type": "application/pdf", "file_size": 3639696, "creation_date": "2025-04-09", "last_modified_date": "2025-03-31"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "73e585e7-34d9-471d-b8da-40e582ea63a3", "node_type": "4", "metadata": {"page_label": "5", "file_name": "2022-04-05 March comments on V3 flag channels.pdf", "file_path": "/Users/unman/ws/slow-productivity-ai/data/2022-04-05 March comments on V3 flag channels.pdf", "file_type": "application/pdf", "file_size": 3639696, "creation_date": "2025-04-09", "last_modified_date": "2025-03-31"}, "hash": "5b457cc1416e4de70c2b50f2a1147504da44d4f35faafb70aa9c6384ab0b261c", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 0, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "3aa57d6a-6eec-441c-b5a1-14086a37061c": {"__data__": {"id_": "3aa57d6a-6eec-441c-b5a1-14086a37061c", "embedding": null, "metadata": {"page_label": "6", "file_name": "2022-04-05 March comments on V3 flag channels.pdf", "file_path": "/Users/unman/ws/slow-productivity-ai/data/2022-04-05 March comments on V3 flag channels.pdf", "file_type": "application/pdf", "file_size": 3639696, "creation_date": "2025-04-09", "last_modified_date": "2025-03-31"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "d08f0456-7928-49f4-9b0e-2ac7c5dfdc07", "node_type": "4", "metadata": {"page_label": "6", "file_name": "2022-04-05 March comments on V3 flag channels.pdf", "file_path": "/Users/unman/ws/slow-productivity-ai/data/2022-04-05 March comments on V3 flag channels.pdf", "file_type": "application/pdf", "file_size": 3639696, "creation_date": "2025-04-09", "last_modified_date": "2025-03-31"}, "hash": "1b4ea450c8168177cf2754c73ac2dc0ba159d1ad10431014415408c532494fa1", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 0, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "6da488a5-5b5e-45b4-8c58-ff75f3ad3444": {"__data__": {"id_": "6da488a5-5b5e-45b4-8c58-ff75f3ad3444", "embedding": null, "metadata": {"page_label": "7", "file_name": "2022-04-05 March comments on V3 flag channels.pdf", "file_path": "/Users/unman/ws/slow-productivity-ai/data/2022-04-05 March comments on V3 flag channels.pdf", "file_type": "application/pdf", "file_size": 3639696, "creation_date": "2025-04-09", "last_modified_date": "2025-03-31"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "54f95092-ae46-43ac-bf40-ce7ec55aed42", "node_type": "4", "metadata": {"page_label": "7", "file_name": "2022-04-05 March comments on V3 flag channels.pdf", "file_path": "/Users/unman/ws/slow-productivity-ai/data/2022-04-05 March comments on V3 flag channels.pdf", "file_type": "application/pdf", "file_size": 3639696, "creation_date": "2025-04-09", "last_modified_date": "2025-03-31"}, "hash": "102151be44a08e3f986f3d7deb7efe96ecb495b12285b894d53e2f6b311482e8", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 0, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "c908f14b-6a02-4674-9421-5f9b2574dcbe": {"__data__": {"id_": "c908f14b-6a02-4674-9421-5f9b2574dcbe", "embedding": null, "metadata": {"page_label": "8", "file_name": "2022-04-05 March comments on V3 flag channels.pdf", "file_path": "/Users/unman/ws/slow-productivity-ai/data/2022-04-05 March comments on V3 flag channels.pdf", "file_type": "application/pdf", "file_size": 3639696, "creation_date": "2025-04-09", "last_modified_date": "2025-03-31"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "ab1fb6b1-a56b-48bb-b17d-051e6e01b935", "node_type": "4", "metadata": {"page_label": "8", "file_name": "2022-04-05 March comments on V3 flag channels.pdf", "file_path": "/Users/unman/ws/slow-productivity-ai/data/2022-04-05 March comments on V3 flag channels.pdf", "file_type": "application/pdf", "file_size": 3639696, "creation_date": "2025-04-09", "last_modified_date": "2025-03-31"}, "hash": "c5a1f13a618ebd18719865a40092eb96ac30ea4b58d451f06b82ca91ae99eccc", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 0, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "d8b9a3ea-1c0e-43a1-a006-167d9d1d986b": {"__data__": {"id_": "d8b9a3ea-1c0e-43a1-a006-167d9d1d986b", "embedding": null, "metadata": {"page_label": "9", "file_name": "2022-04-05 March comments on V3 flag channels.pdf", "file_path": "/Users/unman/ws/slow-productivity-ai/data/2022-04-05 March comments on V3 flag channels.pdf", "file_type": "application/pdf", "file_size": 3639696, "creation_date": "2025-04-09", "last_modified_date": "2025-03-31"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "7441af7e-c080-4d59-8fa6-429c30d46faa", "node_type": "4", "metadata": {"page_label": "9", "file_name": "2022-04-05 March comments on V3 flag channels.pdf", "file_path": "/Users/unman/ws/slow-productivity-ai/data/2022-04-05 March comments on V3 flag channels.pdf", "file_type": "application/pdf", "file_size": 3639696, "creation_date": "2025-04-09", "last_modified_date": "2025-03-31"}, "hash": "41ff005390680b8595ed325c900e5069acdc4ca0423b83943cb686c0b6a0817b", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 0, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "7d788a1e-ca5e-4e16-abff-3c12148adf70": {"__data__": {"id_": "7d788a1e-ca5e-4e16-abff-3c12148adf70", "embedding": null, "metadata": {"page_label": "10", "file_name": "2022-04-05 March comments on V3 flag channels.pdf", "file_path": "/Users/unman/ws/slow-productivity-ai/data/2022-04-05 March comments on V3 flag channels.pdf", "file_type": "application/pdf", "file_size": 3639696, "creation_date": "2025-04-09", "last_modified_date": "2025-03-31"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "0dbdaf45-21a5-4215-9ad2-dc352812ee1a", "node_type": "4", "metadata": {"page_label": "10", "file_name": "2022-04-05 March comments on V3 flag channels.pdf", "file_path": "/Users/unman/ws/slow-productivity-ai/data/2022-04-05 March comments on V3 flag channels.pdf", "file_type": "application/pdf", "file_size": 3639696, "creation_date": "2025-04-09", "last_modified_date": "2025-03-31"}, "hash": "53017b675222a95cd07f9de8680b1634d30b930fa778a2ead0951c122c8a33ac", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 0, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "01f84bf8-d56c-42df-b72f-a7e9d331f6ed": {"__data__": {"id_": "01f84bf8-d56c-42df-b72f-a7e9d331f6ed", "embedding": null, "metadata": {"page_label": "11", "file_name": "2022-04-05 March comments on V3 flag channels.pdf", "file_path": "/Users/unman/ws/slow-productivity-ai/data/2022-04-05 March comments on V3 flag channels.pdf", "file_type": "application/pdf", "file_size": 3639696, "creation_date": "2025-04-09", "last_modified_date": "2025-03-31"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "30d88e7b-2371-49cd-9a31-ebadd9044b9b", "node_type": "4", "metadata": {"page_label": "11", "file_name": "2022-04-05 March comments on V3 flag channels.pdf", "file_path": "/Users/unman/ws/slow-productivity-ai/data/2022-04-05 March comments on V3 flag channels.pdf", "file_type": "application/pdf", "file_size": 3639696, "creation_date": "2025-04-09", "last_modified_date": "2025-03-31"}, "hash": "5a6c48d89db561421dd55574298ed3cd66b75b0266082a7ca8f0151020da446a", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 0, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "1957e903-c62e-4c14-bb42-fdb4277e9651": {"__data__": {"id_": "1957e903-c62e-4c14-bb42-fdb4277e9651", "embedding": null, "metadata": {"page_label": "12", "file_name": "2022-04-05 March comments on V3 flag channels.pdf", "file_path": "/Users/unman/ws/slow-productivity-ai/data/2022-04-05 March comments on V3 flag channels.pdf", "file_type": "application/pdf", "file_size": 3639696, "creation_date": "2025-04-09", "last_modified_date": "2025-03-31"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "d7986193-59ec-42af-af93-28c4c52ad340", "node_type": "4", "metadata": {"page_label": "12", "file_name": "2022-04-05 March comments on V3 flag channels.pdf", "file_path": "/Users/unman/ws/slow-productivity-ai/data/2022-04-05 March comments on V3 flag channels.pdf", "file_type": "application/pdf", "file_size": 3639696, "creation_date": "2025-04-09", "last_modified_date": "2025-03-31"}, "hash": "e3d8bc3394a56e77a5112248da6cc3ee45455386dbc3d6a1e72416a0863489e1", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 0, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "2b794323-5db2-4ee5-ac4c-b93f558915c7": {"__data__": {"id_": "2b794323-5db2-4ee5-ac4c-b93f558915c7", "embedding": null, "metadata": {"page_label": "13", "file_name": "2022-04-05 March comments on V3 flag channels.pdf", "file_path": "/Users/unman/ws/slow-productivity-ai/data/2022-04-05 March comments on V3 flag channels.pdf", "file_type": "application/pdf", "file_size": 3639696, "creation_date": "2025-04-09", "last_modified_date": "2025-03-31"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "a061dff7-55ff-4bbd-9719-f08c1937ee0b", "node_type": "4", "metadata": {"page_label": "13", "file_name": "2022-04-05 March comments on V3 flag channels.pdf", "file_path": "/Users/unman/ws/slow-productivity-ai/data/2022-04-05 March comments on V3 flag channels.pdf", "file_type": "application/pdf", "file_size": 3639696, "creation_date": "2025-04-09", "last_modified_date": "2025-03-31"}, "hash": "6e51a7ed69806195f1ebc4a2868d31a3ad95f25755b11ccc8e3a836d2fc3daf6", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 0, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}}, "docstore/ref_doc_info": {"c6fcb6e8-d381-407c-925f-603220dc5e28": {"node_ids": ["2cbf69c1-1d98-406e-a2b0-60d22243c74d", "0a5ef95e-e2fe-47d4-b86f-ca9d1650652f"], "metadata": {"page_label": "1", "file_name": "1704.02971 (1).pdf", "file_path": "/Users/unman/ws/slow-productivity-ai/data/1704.02971 (1).pdf", "file_type": "application/pdf", "file_size": 488762, "creation_date": "2025-04-09", "last_modified_date": "2025-03-31"}}, "6f0d091d-d372-4ccd-b7f9-9f39ab8d271c": {"node_ids": ["5752e795-6917-47b0-b066-09fa4e500183", "b2b185ea-6c74-4f65-af21-db1cb39f21f3"], "metadata": {"page_label": "2", "file_name": "1704.02971 (1).pdf", "file_path": "/Users/unman/ws/slow-productivity-ai/data/1704.02971 (1).pdf", "file_type": "application/pdf", "file_size": 488762, "creation_date": "2025-04-09", "last_modified_date": "2025-03-31"}}, "00140d49-fe53-4614-b97e-3d76783c7d6c": {"node_ids": ["cf1b47c9-6a63-4e1b-8c56-b00ffe126904", "0220d925-d34a-43fd-b6ab-4a5468486736"], "metadata": {"page_label": "3", "file_name": "1704.02971 (1).pdf", "file_path": "/Users/unman/ws/slow-productivity-ai/data/1704.02971 (1).pdf", "file_type": "application/pdf", "file_size": 488762, "creation_date": "2025-04-09", "last_modified_date": "2025-03-31"}}, "579982a0-8b10-4f70-a5ae-a732543de601": {"node_ids": ["6fe602df-8a43-4a9d-9820-d1163691f80b", "731c2bb4-4e3c-46d2-be43-68810f32dcfa"], "metadata": {"page_label": "4", "file_name": "1704.02971 (1).pdf", "file_path": "/Users/unman/ws/slow-productivity-ai/data/1704.02971 (1).pdf", "file_type": "application/pdf", "file_size": 488762, "creation_date": "2025-04-09", "last_modified_date": "2025-03-31"}}, "1cc7feb7-7921-44cb-81de-f04f84d3ee4f": {"node_ids": ["209a5652-7708-4486-a6b3-dba05c0fe6d0", "d1e3b8f8-f6c1-4a57-a9d9-8d1389ab4a50", "aaee6495-da9a-40e4-b490-3277639432b6"], "metadata": {"page_label": "5", "file_name": "1704.02971 (1).pdf", "file_path": "/Users/unman/ws/slow-productivity-ai/data/1704.02971 (1).pdf", "file_type": "application/pdf", "file_size": 488762, "creation_date": "2025-04-09", "last_modified_date": "2025-03-31"}}, "9205f1a4-d34c-4d87-ab03-56ed03e9a1c6": {"node_ids": ["2cec6d4d-f10f-4436-9f5a-efc5b07d1b00", "e1bbed59-a25d-46f0-b67e-f67925f06c5f", "27d87978-388f-41c9-8f2d-586ae30c1922"], "metadata": {"page_label": "6", "file_name": "1704.02971 (1).pdf", "file_path": "/Users/unman/ws/slow-productivity-ai/data/1704.02971 (1).pdf", "file_type": "application/pdf", "file_size": 488762, "creation_date": "2025-04-09", "last_modified_date": "2025-03-31"}}, "2f8534ef-48a1-4d6c-bfc3-a111f10fda9c": {"node_ids": ["51c38d12-84b8-48c2-9d47-2a65540b7327", "6e5c8941-bfb7-40ae-9c39-e95199b5a90b", "76568e15-15f6-4d8b-af35-ee64625316ff"], "metadata": {"page_label": "7", "file_name": "1704.02971 (1).pdf", "file_path": "/Users/unman/ws/slow-productivity-ai/data/1704.02971 (1).pdf", "file_type": "application/pdf", "file_size": 488762, "creation_date": "2025-04-09", "last_modified_date": "2025-03-31"}}, "c9131b7e-b636-454e-805e-90581068de64": {"node_ids": ["614850f2-eb37-4e8b-aef4-e204324ae9b5"], "metadata": {"page_label": "1", "file_name": "2022-04-05 March comments on V3 flag channels.pdf", "file_path": "/Users/unman/ws/slow-productivity-ai/data/2022-04-05 March comments on V3 flag channels.pdf", "file_type": "application/pdf", "file_size": 3639696, "creation_date": "2025-04-09", "last_modified_date": "2025-03-31"}}, "2ec865cf-e9fe-47a2-8e3e-1061a24bab5e": {"node_ids": ["4745628e-ab0f-4ab6-870d-b23b79b8e616"], "metadata": {"page_label": "2", "file_name": "2022-04-05 March comments on V3 flag channels.pdf", "file_path": "/Users/unman/ws/slow-productivity-ai/data/2022-04-05 March comments on V3 flag channels.pdf", "file_type": "application/pdf", "file_size": 3639696, "creation_date": "2025-04-09", "last_modified_date": "2025-03-31"}}, "f5b274b5-39d7-4b1f-97a8-39fdd91a769f": {"node_ids": ["8892770e-ead6-4bb6-ae8f-02ffb2b4b571"], "metadata": {"page_label": "3", "file_name": "2022-04-05 March comments on V3 flag channels.pdf", "file_path": "/Users/unman/ws/slow-productivity-ai/data/2022-04-05 March comments on V3 flag channels.pdf", "file_type": "application/pdf", "file_size": 3639696, "creation_date": "2025-04-09", "last_modified_date": "2025-03-31"}}, "2cfb4c26-85e2-4a90-952a-68981772a34f": {"node_ids": ["e3db68b8-f175-4ef7-a276-f8ddfec754e5"], "metadata": {"page_label": "4", "file_name": "2022-04-05 March comments on V3 flag channels.pdf", "file_path": "/Users/unman/ws/slow-productivity-ai/data/2022-04-05 March comments on V3 flag channels.pdf", "file_type": "application/pdf", "file_size": 3639696, "creation_date": "2025-04-09", "last_modified_date": "2025-03-31"}}, "73e585e7-34d9-471d-b8da-40e582ea63a3": {"node_ids": ["1e572200-cde2-4669-a957-cf3993646f6d"], "metadata": {"page_label": "5", "file_name": "2022-04-05 March comments on V3 flag channels.pdf", "file_path": "/Users/unman/ws/slow-productivity-ai/data/2022-04-05 March comments on V3 flag channels.pdf", "file_type": "application/pdf", "file_size": 3639696, "creation_date": "2025-04-09", "last_modified_date": "2025-03-31"}}, "d08f0456-7928-49f4-9b0e-2ac7c5dfdc07": {"node_ids": ["3aa57d6a-6eec-441c-b5a1-14086a37061c"], "metadata": {"page_label": "6", "file_name": "2022-04-05 March comments on V3 flag channels.pdf", "file_path": "/Users/unman/ws/slow-productivity-ai/data/2022-04-05 March comments on V3 flag channels.pdf", "file_type": "application/pdf", "file_size": 3639696, "creation_date": "2025-04-09", "last_modified_date": "2025-03-31"}}, "54f95092-ae46-43ac-bf40-ce7ec55aed42": {"node_ids": ["6da488a5-5b5e-45b4-8c58-ff75f3ad3444"], "metadata": {"page_label": "7", "file_name": "2022-04-05 March comments on V3 flag channels.pdf", "file_path": "/Users/unman/ws/slow-productivity-ai/data/2022-04-05 March comments on V3 flag channels.pdf", "file_type": "application/pdf", "file_size": 3639696, "creation_date": "2025-04-09", "last_modified_date": "2025-03-31"}}, "ab1fb6b1-a56b-48bb-b17d-051e6e01b935": {"node_ids": ["c908f14b-6a02-4674-9421-5f9b2574dcbe"], "metadata": {"page_label": "8", "file_name": "2022-04-05 March comments on V3 flag channels.pdf", "file_path": "/Users/unman/ws/slow-productivity-ai/data/2022-04-05 March comments on V3 flag channels.pdf", "file_type": "application/pdf", "file_size": 3639696, "creation_date": "2025-04-09", "last_modified_date": "2025-03-31"}}, "7441af7e-c080-4d59-8fa6-429c30d46faa": {"node_ids": ["d8b9a3ea-1c0e-43a1-a006-167d9d1d986b"], "metadata": {"page_label": "9", "file_name": "2022-04-05 March comments on V3 flag channels.pdf", "file_path": "/Users/unman/ws/slow-productivity-ai/data/2022-04-05 March comments on V3 flag channels.pdf", "file_type": "application/pdf", "file_size": 3639696, "creation_date": "2025-04-09", "last_modified_date": "2025-03-31"}}, "0dbdaf45-21a5-4215-9ad2-dc352812ee1a": {"node_ids": ["7d788a1e-ca5e-4e16-abff-3c12148adf70"], "metadata": {"page_label": "10", "file_name": "2022-04-05 March comments on V3 flag channels.pdf", "file_path": "/Users/unman/ws/slow-productivity-ai/data/2022-04-05 March comments on V3 flag channels.pdf", "file_type": "application/pdf", "file_size": 3639696, "creation_date": "2025-04-09", "last_modified_date": "2025-03-31"}}, "30d88e7b-2371-49cd-9a31-ebadd9044b9b": {"node_ids": ["01f84bf8-d56c-42df-b72f-a7e9d331f6ed"], "metadata": {"page_label": "11", "file_name": "2022-04-05 March comments on V3 flag channels.pdf", "file_path": "/Users/unman/ws/slow-productivity-ai/data/2022-04-05 March comments on V3 flag channels.pdf", "file_type": "application/pdf", "file_size": 3639696, "creation_date": "2025-04-09", "last_modified_date": "2025-03-31"}}, "d7986193-59ec-42af-af93-28c4c52ad340": {"node_ids": ["1957e903-c62e-4c14-bb42-fdb4277e9651"], "metadata": {"page_label": "12", "file_name": "2022-04-05 March comments on V3 flag channels.pdf", "file_path": "/Users/unman/ws/slow-productivity-ai/data/2022-04-05 March comments on V3 flag channels.pdf", "file_type": "application/pdf", "file_size": 3639696, "creation_date": "2025-04-09", "last_modified_date": "2025-03-31"}}, "a061dff7-55ff-4bbd-9719-f08c1937ee0b": {"node_ids": ["2b794323-5db2-4ee5-ac4c-b93f558915c7"], "metadata": {"page_label": "13", "file_name": "2022-04-05 March comments on V3 flag channels.pdf", "file_path": "/Users/unman/ws/slow-productivity-ai/data/2022-04-05 March comments on V3 flag channels.pdf", "file_type": "application/pdf", "file_size": 3639696, "creation_date": "2025-04-09", "last_modified_date": "2025-03-31"}}}}